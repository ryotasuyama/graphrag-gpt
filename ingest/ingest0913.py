from pathlib import Path
import re
import shutil
from typing import List, Tuple, Dict, Any, Optional

import config
from langchain_core.documents import Document
from langchain_neo4j import Neo4jGraph
from neo4j.exceptions import ServiceUnavailable
from langchain_community.graphs.graph_document import GraphDocument, Node, Relationship
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_experimental.graph_transformers import LLMGraphTransformer
from langchain_core.prompts import ChatPromptTemplate

# --- å®šæ•°å®šç¾© (å¤‰æ›´ãªã—) ---
DATA_DIR = Path("data")
NEO4J_URI = config.NEO4J_URI
NEO4J_USER = config.NEO4J_USER
NEO4J_PASSWORD = config.NEO4J_PASSWORD
NEO4J_DATABASE = getattr(config, "NEO4J_DATABASE", "neo4j")

API_TXT_CANDIDATES = [
    Path("/mnt/data/api.txt"),
    Path("api.txt"),
    DATA_DIR / "api.txt",
]

API_ARG_TXT_CANDIDATES = [
    Path("/mnt/data/api_arg.txt"),
    Path("api_arg.txt"),
    DATA_DIR / "api_arg.txt",
]

CHROMA_PERSIST_DIR = DATA_DIR / "chroma_db"
OPENAI_API_KEY = config.OPENAI_API_KEY

# --- ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ãƒ»ãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–é–¢æ•° (å¤‰æ›´ãªã—) ---

def _read_api_text() -> str:
    """api.txt ã‚’å€™è£œãƒ‘ã‚¹ã‹ã‚‰èª­ã¿è¾¼ã‚€"""
    for p in API_TXT_CANDIDATES:
        if p.exists():
            return p.read_text(encoding="utf-8")
    raise FileNotFoundError("api.txt ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚/mnt/data/api.txt ã¾ãŸã¯ ./api.txt ã‚’ç”¨æ„ã—ã¦ãã ã•ã„ã€‚")

def _read_api_arg_text() -> str:
    """api_arg.txt ã‚’å€™è£œãƒ‘ã‚¹ã‹ã‚‰èª­ã¿è¾¼ã‚€"""
    for p in API_ARG_TXT_CANDIDATES:
        if p.exists():
            return p.read_text(encoding="utf-8")
    raise FileNotFoundError("api_arg.txt ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

def _read_script_files() -> List[Tuple[str, str]]:
    """data ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã® .py ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã™ã¹ã¦èª­ã¿è¾¼ã‚€"""
    script_files = []
    if not DATA_DIR.exists():
        return []
    
    for p in DATA_DIR.glob("*.py"):
        if p.is_file():
            script_files.append((p.name, p.read_text(encoding="utf-8")))
            
    return script_files

def _normalize_text(text: str) -> str:
    """
    æ”¹è¡Œ/ã‚¿ãƒ–/ç©ºç™½ã®æºã‚Œã‚’æ­£è¦åŒ–ã€‚
    """
    text = text.replace("\ufeff", "")
    text = text.replace("\r\n", "\n").replace("\r", "\n")
    text = "\n".join(line.rstrip() for line in text.split("\n"))
    text = text.replace("\t", " ")
    text = re.sub(r"[ \u00A0\u3000]+", " ", text)
    return text

# --- ã“ã“ã‹ã‚‰: ingest0901.py ã‚’å‚è€ƒã«ã—ãŸãƒ—ãƒ­ã‚°ãƒ©ãƒ ã«ã‚ˆã‚‹APIä»•æ§˜æ›¸è§£æé–¢æ•° ---

def _to_object_id_from_header(header: str) -> str:
    """
    'â– Partã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ¡ã‚½ãƒƒãƒ‰' â†’ 'Part'
    æœ«å°¾ã® 'ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ' ã‚„ 'ã®ãƒ¡ã‚½ãƒƒãƒ‰' ã‚’é©å®œè½ã¨ã—ã¦ Object åã‚’æŠ½å‡º
    """
    s = header.strip()
    s = re.sub(r"^â– ", "", s)
    s = s.replace("ã®ãƒ¡ã‚½ãƒƒãƒ‰", "")
    s = s.replace("ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ", "")
    return s.strip()

def _guess_return_type_from_desc(desc: str) -> str:
    """
    è¿”ã‚Šå€¤èª¬æ˜ã‹ã‚‰ãŠãŠã¾ã‹ã«å‹ã‚’æ¨å®šã€‚
    ãƒ»'ID' / 'Id' / 'è¦ç´ ID' å«ã‚€ â†’ 'ID'
    ãƒ»ãã‚Œä»¥å¤–ã¯ 'ä¸æ˜'
    """
    d = desc or ""
    if re.search(r"\bID\b", d, flags=re.IGNORECASE) or ("è¦ç´ ID" in d):
        return "ID"
    return "ä¸æ˜"

def _parse_api_specs(text: str) -> List[Dict[str, Any]]:
    """
    api.txt ã‹ã‚‰æ§‹é€ åŒ–ã•ã‚ŒãŸé…åˆ—ã‚’è¿”ã™
    """
    lines = text.split("\n")
    closing_pat = re.compile(r"\)\s*;?(?:\s*//.*)?$")
    param_pat = re.compile(
        r"^([A-Za-z_][A-Za-z0-9_]*)\s*,?\s*//\s*([^:ï¼š]+)\s*[:ï¼š]\s*(.*)$"
    )
    method_start_pat = re.compile(r"^([A-Za-z_][A-Za-z0-9_]*)\s*\($")
    header_pat = re.compile(r"^â– .+ã®ãƒ¡ã‚½ãƒƒãƒ‰$")
    title_pat = re.compile(r"^ã€‡(.+)$")
    ret_pat = re.compile(r"^è¿”ã‚Šå€¤[:ï¼š]\s*(.+)$")

    current_object = None
    current_title = None
    current_return_desc = None
    current_entry: Optional[Dict[str, Any]] = None
    entries: List[Dict[str, Any]] = []
    i = 0
    n = len(lines)
    while i < n:
        line = lines[i].strip()
        if header_pat.match(line):
            current_object = _to_object_id_from_header(line)
            current_title = None
            current_return_desc = None
            i += 1
            continue
        m_title = title_pat.match(line)
        if m_title:
            current_title = m_title.group(1).strip()
            i += 1
            if i < n:
                m_ret = ret_pat.match(lines[i].strip())
                if m_ret:
                    current_return_desc = m_ret.group(1).strip()
                    i += 1
            continue
        m_start = method_start_pat.match(line)
        if m_start:
            method_name = m_start.group(1)
            current_entry = {
                "object": current_object or "Object",
                "title_jp": current_title or "",
                "name": method_name,
                "return_desc": current_return_desc or "",
                "return_type": _guess_return_type_from_desc(current_return_desc or ""),
                "params": [],
            }
            i += 1
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åé›†é–‹å§‹
            while i < n:
                param_line = lines[i].strip()
                if closing_pat.search(param_line):
                    # æœ€å¾Œã®è¡Œã®å‡¦ç†
                    idx_close = param_line.rfind(")")
                    before = param_line[:idx_close]
                    if "//" in before: # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã‚«ãƒƒã‚³å†…ã«ã‚ã‚‹å ´åˆ
                         pm = param_pat.match(before)
                         if pm:
                            pname, ptype, pdesc = pm.groups()
                            current_entry["params"].append({"name": pname, "type": ptype.strip(), "description": pdesc.strip()})
                    entries.append(current_entry)
                    current_entry = None
                    break
                
                pm = param_pat.match(param_line)
                if pm:
                    pname, ptype, pdesc = pm.groups()
                    current_entry["params"].append(
                        {"name": pname, "type": ptype.strip(), "description": pdesc.strip()}
                    )
                i += 1
            i += 1
            continue
        i += 1
    return entries

def _parse_data_type_descriptions(text: str) -> Dict[str, str]:
    """
    api_arg.txt ã‚’è§£æã—ã€ãƒ‡ãƒ¼ã‚¿å‹åã¨ãã®èª¬æ˜ã®è¾æ›¸ã‚’è¿”ã™ã€‚
    """
    descriptions = {}
    current_type = None
    current_desc_lines = []
    
    normalized_text = _normalize_text(text)
    
    for line in normalized_text.split("\n"):
        line = line.strip()
        if not line:
            continue
        if line.startswith("â– "):
            if current_type and current_desc_lines:
                descriptions[current_type] = "\n".join(current_desc_lines).strip()
            current_type = line.replace("â– ", "").strip()
            current_desc_lines = []
        elif current_type:
            current_desc_lines.append(line)
    if current_type and current_desc_lines:
        descriptions[current_type] = "\n".join(current_desc_lines).strip()
    return descriptions

def extract_triples_from_specs(
    api_text: str, type_descriptions: Dict[str, str]
    ) -> Tuple[List[Dict[str, Any]], Dict[str, Dict[str, Any]]]:
    """
    ä»•æ§˜ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒãƒ¼ãƒ‰/ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒˆãƒªãƒ—ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    entries = _parse_api_specs(api_text)

    triples: List[Dict[str, Any]] = []
    node_props: Dict[str, Dict[str, Any]] = {}

    def _clean_type_name(type_name: str) -> str:
        return re.sub(r"\s*\(.+\)$", "", type_name).strip()

    def create_data_type_node(raw_type_name: str) -> str:
        cleaned_type_name = _clean_type_name(raw_type_name)
        if cleaned_type_name not in node_props:
            properties = {"name": cleaned_type_name}
            description = type_descriptions.get(cleaned_type_name)
            if description:
                properties["description"] = description
            node_props[cleaned_type_name] = {"type": "DataType", "properties": properties}
        return cleaned_type_name

    for e in entries:
        obj_name = e["object"] or "Object"
        method_name = e["name"]
        title_jp = e.get("title_jp", "")
        ret_desc = e.get("return_desc", "")
        ret_type_raw = e.get("return_type", "ä¸æ˜")
        params = e.get("params", [])

        node_props.setdefault(obj_name, {"type": "Object", "properties": {"name": obj_name}})
        node_props.setdefault(method_name, {"type": "Method", "properties": {"name": method_name, "description": title_jp}})
        ret_node_id = f"{method_name}_ReturnValue"
        node_props.setdefault(ret_node_id, {"type": "ReturnValue", "properties": {"description": ret_desc}})
        
        cleaned_ret_type = create_data_type_node(ret_type_raw)

        triples.append({"source": method_name, "source_type": "Method", "label": "BELONGS_TO", "target": obj_name, "target_type": "Object"})
        triples.append({"source": method_name, "source_type": "Method", "label": "HAS_RETURNS", "target": ret_node_id, "target_type": "ReturnValue"})
        triples.append({"source": ret_node_id, "source_type": "ReturnValue", "label": "HAS_TYPE", "target": cleaned_ret_type, "target_type": "DataType"})

        for i, p in enumerate(params):
            pname, ptype_raw, pdesc = p.get("name", "Param"), p.get("type", "å‹"), p.get("description", "")
            param_node_id = f"{method_name}_{pname}"
            node_props.setdefault(param_node_id, {"type": "Parameter", "properties": {"name": pname, "description": pdesc, "order": i}})
            cleaned_ptype = create_data_type_node(ptype_raw)
            triples.append({"source": method_name, "source_type": "Method", "label": "HAS_PARAMETER", "target": param_node_id, "target_type": "Parameter"})
            triples.append({"source": param_node_id, "source_type": "Parameter", "label": "HAS_TYPE", "target": cleaned_ptype, "target_type": "DataType"})
    return triples, node_props

def _triples_to_graph_documents(triples: List[Dict[str, Any]], node_props: Dict[str, Dict[str, Any]]) -> List[GraphDocument]:
    """
    ãƒˆãƒªãƒ—ãƒ«ã¨ãƒãƒ¼ãƒ‰å±æ€§ã‹ã‚‰ GraphDocument ç¾¤ã‚’ä½œã‚‹
    """
    node_map: Dict[str, Node] = {}
    for node_id, meta in node_props.items():
        if node_id in node_map:
            existing_node = node_map[node_id]
            existing_node.properties.update(meta.get("properties", {}))
        else:
            ntype = meta["type"]
            props = meta.get("properties", {})
            node_map[node_id] = Node(id=node_id, type=ntype, properties=props)
    
    rels: List[Relationship] = []
    for t in triples:
        source_node = node_map.get(t["source"]) or Node(id=t["source"], type=t["source_type"])
        target_node = node_map.get(t["target"]) or Node(id=t["target"], type=t["target_type"])
        rels.append(Relationship(source=source_node, target=target_node, type=t["label"], properties={}))
    
    doc = Document(page_content="API Spec and Example graph")
    gdoc = GraphDocument(nodes=list(node_map.values()), relationships=rels, source=doc)
    return [gdoc]

# --- ã“ã“ã¾ã§: ingest0901.py ã‚’å‚è€ƒã«ã—ãŸãƒ—ãƒ­ã‚°ãƒ©ãƒ ã«ã‚ˆã‚‹APIä»•æ§˜æ›¸è§£æé–¢æ•° ---
def _rebuild_graph_in_neo4j(graph_docs: List[GraphDocument]) -> Tuple[int, int]:
    """
    Neo4j ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦ã‹ã‚‰ GraphDocument ã‚’æŠ•å…¥ã™ã‚‹
    """
    graph = Neo4jGraph(
        url=NEO4J_URI,
        username=NEO4J_USER,
        password=NEO4J_PASSWORD,
        database=NEO4J_DATABASE,
    )
    
    print("ğŸ§¹ Neo4jã®æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ä¸­...")
    delete_query = "MATCH (n) DETACH DELETE n"
    graph.query(delete_query)
    
    print(f"\nğŸš€ Neo4jã«ãƒ‡ãƒ¼ã‚¿ã‚’æŠ•å…¥ä¸­...")
    
    graph.add_graph_documents(graph_docs)
    
    res_nodes = graph.query("MATCH (n) RETURN count(n) AS c")
    res_rels = graph.query("MATCH ()-[r]->() RETURN count(r) AS c")
    return int(res_nodes[0]["c"]), int(res_rels[0]["c"])


def _build_and_load_chroma(docs_for_vectorstore: List[Document]) -> None:
    """
    ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒªã‚¹ãƒˆã‹ã‚‰ãƒ™ã‚¯ãƒˆãƒ«DB (Chroma) ã‚’æ§‹ç¯‰ãƒ»æ°¸ç¶šåŒ–ã™ã‚‹
    """
    print("\nğŸš€ ChromaDBã®ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆãƒ»ä¿å­˜ä¸­...")

    if CHROMA_PERSIST_DIR.exists():
        shutil.rmtree(CHROMA_PERSIST_DIR)
    CHROMA_PERSIST_DIR.mkdir(exist_ok=True)

    try:
        embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
        vectorstore = Chroma.from_documents(
            documents=docs_for_vectorstore,
            embedding=embeddings,
            persist_directory=str(CHROMA_PERSIST_DIR),
        )
        print(
            f"âœ” Chroma DB created and persisted with {len(docs_for_vectorstore)} documents at: {CHROMA_PERSIST_DIR}"
        )
    except Exception as e:
        print(f"âš  Chroma DBã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

# --- Neo4jã‚°ãƒ©ãƒ•æ§‹ç¯‰é–¢æ•° (ä¿®æ­£) ---

def _build_and_load_neo4j() -> None:
    """
    APIä»•æ§˜æ›¸ã‚’ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ã€ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹ã‚’LLMã§è§£æã—ã€ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰ã—ã¦Neo4jã«ãƒ­ãƒ¼ãƒ‰ã™ã‚‹
    """
    gdocs = []  # æŠ½å‡ºã—ãŸã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ

    # --- 1. APIä»•æ§˜æ›¸ã‚’ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§è§£æ ---
    print("ğŸ“„ APIä»•æ§˜æ›¸ã‚’ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§è§£æä¸­...")
    try:
        api_text = _normalize_text(_read_api_text())
        api_arg_text = _normalize_text(_read_api_arg_text())
        
        type_descriptions = _parse_data_type_descriptions(api_arg_text)
        spec_triples, spec_node_props = extract_triples_from_specs(api_text, type_descriptions)
        
        spec_gdocs = _triples_to_graph_documents(spec_triples, spec_node_props)
        gdocs.extend(spec_gdocs)
        print(f"âœ” APIä»•æ§˜æ›¸ã‹ã‚‰ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ãƒˆãƒªãƒ—ãƒ«ã‚’æŠ½å‡º: {len(spec_triples)} ä»¶")
    except FileNotFoundError as e:
        print(f"âš  APIä»•æ§˜æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€è§£æã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™: {e}")

    # --- 2. ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹ã‚’LLMã§è§£æ ---
    print("\nğŸ ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹ã‚’èª­ã¿è¾¼ã¿ã€LLMã§è§£æä¸­...")
    script_docs = []
    script_files = _read_script_files()
    for script_name, script_content in script_files:
        script_docs.append(Document(page_content=script_content, metadata={"source": script_name}))
    
    if script_docs:
        print(f"   - {len(script_docs)}ä»¶ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å¯¾è±¡ã«ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºä¸­...")
        llm = ChatOpenAI(temperature=1, model_name="gpt-5-mini", openai_api_key=OPENAI_API_KEY)
        
        # ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        script_prompt = ChatPromptTemplate.from_messages(
            [
                ("system",
                 """
                 ã‚ãªãŸã¯ã€Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’è§£æã—ã€é–¢æ•°ã‚„ã‚¯ãƒ©ã‚¹ã®åˆ©ç”¨é–¢ä¿‚ã‚’çŸ¥è­˜ã‚°ãƒ©ãƒ•ã¨ã—ã¦æŠ½å‡ºã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚
                 ã©ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒã©ã®é–¢æ•°ã‚’å‘¼ã³å‡ºã—ã¦ã„ã‚‹ã‹ã‚’ç‰¹å®šã—ã¦ãã ã•ã„ã€‚

                 # çŸ¥è­˜ã‚°ãƒ©ãƒ•ã®ã‚¹ã‚­ãƒ¼ãƒå®šç¾©
                 - ãƒãƒ¼ãƒ‰ "Script": å‡¦ç†ãŒè¨˜è¿°ã•ã‚ŒãŸã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã€‚
                 - ãƒãƒ¼ãƒ‰ "Function": ã‚¹ã‚¯ãƒªãƒ—ãƒˆå†…ã§ä½¿ç”¨ã•ã‚Œã‚‹é–¢æ•°ã€‚
                 - é–¢ä¿‚ "USES": Script -> Function (ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒé–¢æ•°ã‚’ä½¿ç”¨ã™ã‚‹)
                 - é–¢ä¿‚ "CALLS": Function -> Function (é–¢æ•°ãŒåˆ¥ã®é–¢æ•°ã‚’å‘¼ã³å‡ºã™)
                 
                 # æŒ‡ç¤º
                 - ä¸Šè¨˜ã®ã‚¹ã‚­ãƒ¼ãƒã«å³å¯†ã«å¾“ã£ã¦ãã ã•ã„ã€‚
                 - ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«åã¨ã€ãã“ã§åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹é–¢æ•°åã®é–¢ä¿‚ã‚’æŠ½å‡ºã™ã‚‹ã“ã¨ã«é›†ä¸­ã—ã¦ãã ã•ã„ã€‚
                 """),
                ("human", "ä»¥ä¸‹ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‹ã‚‰çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„:\n\n{input}"),
            ]
        )
        script_transformer = LLMGraphTransformer(llm=llm, prompt=script_prompt)
        script_gdocs = script_transformer.convert_to_graph_documents(script_docs)
        gdocs.extend(script_gdocs)
        print(f"âœ” ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹ã‹ã‚‰ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¾ã—ãŸã€‚")
    else:
        print("   - è§£æå¯¾è±¡ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    # --- 3. Neo4jã¸ã®ãƒ‡ãƒ¼ã‚¿æŠ•å…¥ ---
    if not gdocs:
        print("\nâš  ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãŒç”Ÿæˆã•ã‚Œãªã‹ã£ãŸãŸã‚ã€Neo4jã®æ›´æ–°ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return
        
    try:
        node_count, rel_count = _rebuild_graph_in_neo4j(gdocs)
        print(f"âœ” ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å†æ§‹ç¯‰ãŒå®Œäº†ã—ã¾ã—ãŸ: ãƒãƒ¼ãƒ‰={node_count}, ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ãƒƒãƒ—={rel_count}")
    except ServiceUnavailable as se:
        print(f"âš  Neo4j ã¸ã®æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ: {se}")
        print("   Neo4jã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ã€æ¥ç¶šæƒ…å ±ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    except Exception as e:
        print(f"âš  ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ§‹ç¯‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# --- mainé–¢æ•° (å¤‰æ›´ãªã—) ---

def main() -> None:
    """
    ãƒ¡ã‚¤ãƒ³å‡¦ç†
    """
    # ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ (Neo4j) ã‚’æ§‹ç¯‰
    _build_and_load_neo4j()

    # ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ (Chroma) ã‚’æ§‹ç¯‰
    print("\n--- ChromaDBæ§‹ç¯‰ãƒ—ãƒ­ã‚»ã‚¹ ---")
    
    docs_for_vectorstore: List[Document] = []
    
    # 1. APIä»•æ§˜ã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆ
    try:
        api_text = _read_api_text()
        content_api = _normalize_text(api_text)
        docs_for_vectorstore.append(Document(
            page_content=content_api, 
            metadata={"source": "api_spec"}
        ))
        print(f"âœ” APIä»•æ§˜æ›¸ã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’1ä»¶ä½œæˆã—ã¾ã—ãŸã€‚")
    except FileNotFoundError:
        print("âš  APIä»•æ§˜æ›¸ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€Chromaã¸ã®ç™»éŒ²ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")

    # 2. ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹ã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆ
    script_files = _read_script_files()
    if script_files:
        for script_name, script_content in script_files:
            content = (
                f"ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹: {script_name}\n\n```python\n{script_content}\n```"
            )
            metadata = {
                "source": "script_example",
                "script_name": script_name,
            }
            docs_for_vectorstore.append(Document(page_content=content, metadata=metadata))
        print(f"âœ” {len(script_files)}ä»¶ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹ã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆã—ã¾ã—ãŸã€‚")
    else:
        print("âš  ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    
    # æƒ…å ±ã‚’æ¸¡ã—ã¦ChromaDBã‚’æ§‹ç¯‰
    if docs_for_vectorstore:
        _build_and_load_chroma(docs_for_vectorstore)
    else:
        print("âš  ChromaDBã«ç™»éŒ²ã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")


if __name__ == "__main__":
    main()