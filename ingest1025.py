from tree_sitter import Language, Parser
import tree_sitter_python as tspython

from pathlib import Path
import re
import json
from typing import List, Dict, Any, Tuple
import shutil

import config
from langchain_core.documents import Document
from langchain_neo4j import Neo4jGraph
from neo4j.exceptions import ServiceUnavailable
from langchain_community.graphs.graph_document import GraphDocument, Node, Relationship
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings ,ChatOpenAI

DATA_DIR = Path("data")
NEO4J_URI = config.NEO4J_URI
NEO4J_USER = config.NEO4J_USER
NEO4J_PASSWORD = config.NEO4J_PASSWORD
NEO4J_DATABASE = getattr(config, "NEO4J_DATABASE", "neo4j")

# api.txt é–¢é€£ã®å®šç¾©ã‚’å‰Šé™¤ (API_TXT_CANDIDATES)

API_ARG_TXT_CANDIDATES = [
    Path("/mnt/data/api_arg.txt"),
    Path("api_arg.txt"),
    DATA_DIR / "api_arg.txt",
]

PY_LANGUAGE = Language(tspython.language())
parser = Parser(PY_LANGUAGE)

CHROMA_PERSIST_DIR = DATA_DIR / "chroma_db"
OPENAI_API_KEY = config.OPENAI_API_KEY

llm = ChatOpenAI(
    temperature=0, 
    model_name="gpt-5.2", 
    openai_api_key=OPENAI_API_KEY,
    # request_timeout=600
) 

def _read_api_arg_text() -> str:
    """api_arg.txt ã‚’å€™è£œãƒ‘ã‚¹ã‹ã‚‰èª­ã¿è¾¼ã‚€"""
    for p in API_ARG_TXT_CANDIDATES:
        if p.exists():
            return p.read_text(encoding="utf-8")
    raise FileNotFoundError("api_arg.txt ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

def _read_script_files() -> List[Tuple[str, str]]:
    """data ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã® .py ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã™ã¹ã¦èª­ã¿è¾¼ã‚€"""
    script_files = []
    if not DATA_DIR.exists():
        return []
    
    for p in DATA_DIR.glob("*.py"):
        if p.is_file():
            script_files.append((p.name, p.read_text(encoding="utf-8")))
            
    return script_files

def extract_triples_from_script(
    script_path: str, script_text: str
    ) -> Tuple[List[Dict[str, Any]], Dict[str, Dict[str, Any]]]:
    """ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€ãƒãƒ¼ãƒ‰/ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒˆãƒªãƒ—ãƒ«ã‚’ç”Ÿæˆã™ã‚‹"""
    triples: List[Dict[str, Any]] = []
    node_props: Dict[str, Dict[str, Any]] = {}

    script_node_id = script_path
    node_props[script_node_id] = {
        "type": "ScriptExample",
        "properties": {
            "name": script_path,
            "code": script_text
        }
    }

    all_methods_in_script = set()

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ã‚’è¿½è·¡ã™ã‚‹ãŸã‚ã€ã‚¹ã‚¯ãƒªãƒ—ãƒˆå†…ã§å¤‰æ•°ãŒã©ã®ãƒ¡ã‚½ãƒƒãƒ‰å‘¼ã³å‡ºã—ã‹ã‚‰ç”Ÿæˆã•ã‚ŒãŸã‹ã‚’è¨˜éŒ²ã™ã‚‹
    # { "å¤‰æ•°å": "ç”Ÿæˆå…ƒã®MethodCallãƒãƒ¼ãƒ‰ID" }
    variable_to_source_call_id: Dict[str, str] = {}

    method_calls_in_script = _extract_method_calls_from_script(script_text)
    prev_call_node_id = None

    for i, call in enumerate(method_calls_in_script):
        method_name = call["method_name"]
        all_methods_in_script.add(method_name)
        
        call_node_id = f"{script_path}_call_{i}"
        node_props[call_node_id] = {
            "type": "MethodCall",
            "properties": {"code": call["full_text"], "order": i}
        }
        
        # ScriptExampleãƒãƒ¼ãƒ‰ã«ç›´æ¥CONTAINSãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§é–¢é€£ä»˜ã‘ã‚‹
        triples.append({
            "source": script_node_id, "source_type": "ScriptExample",
            "label": "CONTAINS", "target": call_node_id, "target_type": "MethodCall"
        })
        
        triples.append({
            "source": call_node_id, "source_type": "MethodCall",
            "label": "CALLS", "target": method_name, "target_type": "Method"
        })

        # --- ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼è§£æ ---
        # 1. ç¾åœ¨ã®ãƒ¡ã‚½ãƒƒãƒ‰å‘¼ã³å‡ºã—ã®å¼•æ•°ã‚’è§£æã™ã‚‹
        arguments_node = call["node"].child_by_field_name("arguments")
        if arguments_node:
            # å¼•æ•°ãƒãƒ¼ãƒ‰å†…ã®ã™ã¹ã¦ã®å¤‰æ•°åï¼ˆidentifierï¼‰ã‚’å†å¸°çš„ã«æ¢ç´¢
            arg_vars = []
            def find_identifiers(n):
                if n.type == 'identifier':
                    arg_vars.append(n.text.decode('utf8'))
                for child in n.children:
                    find_identifiers(child)
            find_identifiers(arguments_node)
            
            # è¦‹ã¤ã‹ã£ãŸå¤‰æ•°ã«ã¤ã„ã¦ã€ãã‚ŒãŒä»¥å‰ã®ãƒ¡ã‚½ãƒƒãƒ‰å‘¼ã³å‡ºã—ã®çµæœã§ã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            for var_name in set(arg_vars): # setã§é‡è¤‡ã—ãŸãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é˜²æ­¢
                if var_name in variable_to_source_call_id:
                    source_call_node_id = variable_to_source_call_id[var_name]
                    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ã‚’ç¤ºã™ PASSES_RESULT_TO ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
                    triples.append({
                        "source": source_call_node_id, "source_type": "MethodCall",
                        "label": "PASSES_RESULT_TO", 
                        "target": call_node_id, "target_type": "MethodCall"
                    })

        # 2. ç¾åœ¨ã®ãƒ¡ã‚½ãƒƒãƒ‰å‘¼ã³å‡ºã—ã®çµæœãŒå¤‰æ•°ã«ä»£å…¥ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if call["assigned_to"]:
            # å¤‰æ•°åã¨ç¾åœ¨ã®å‘¼ã³å‡ºã—IDã‚’ãƒãƒƒãƒ”ãƒ³ã‚°ã—ã€å¾Œç¶šã®å‘¼ã³å‡ºã—ã§å‚ç…§ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
            variable_to_source_call_id[call["assigned_to"]] = call_node_id
        # --- ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼è§£æã“ã“ã¾ã§ ---

        if prev_call_node_id:
            triples.append({
                "source": prev_call_node_id, "source_type": "MethodCall",
                "label": "NEXT", "target": call_node_id, "target_type": "MethodCall"
            })
        
        prev_call_node_id = call_node_id

    for method_name in all_methods_in_script:
        triples.append({
            "source": script_node_id, "source_type": "ScriptExample",
            "label": "IS_EXAMPLE_OF", "target": method_name, "target_type": "Method"
        })

    return triples, node_props

def _extract_graph_from_specs_with_llm(raw_text: str) -> Dict[str, List[Dict[str, Any]]]:
    """LLMã‚’ä½¿ã£ã¦APIä»•æ§˜æ›¸ã®ç”Ÿãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒãƒ¼ãƒ‰ã¨ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡ºã™ã‚‹"""
    prompt = f"""
        ã‚ãªãŸã¯APIä»•æ§˜æ›¸ã‚’è§£æã—ã€çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰ã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚
        ä»¥ä¸‹ã®APIä»•æ§˜æ›¸ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€æŒ‡å®šã•ã‚ŒãŸã‚¹ã‚­ãƒ¼ãƒã«å¾“ã£ã¦ãƒãƒ¼ãƒ‰ã¨ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡ºã—ã€JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

        --- ã‚°ãƒ©ãƒ•ã®ã‚¹ã‚­ãƒ¼ãƒå®šç¾© ---
        1.  **ãƒãƒ¼ãƒ‰ã®ç¨®é¡ã¨ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£:**
            - `Object`: APIã®æ“ä½œå¯¾è±¡ã¨ãªã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€‚ (ä¾‹: "Part")
                - `id`: ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå (ä¾‹: "Part")
                - `properties`: {{ "name": "ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå" }}
            - `Method`: ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å±ã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰ã€‚
                - `id`: ãƒ¡ã‚½ãƒƒãƒ‰å (ä¾‹: "CreateVariable")
                - `properties`: {{ "name": "ãƒ¡ã‚½ãƒƒãƒ‰å", "description": "ãƒ¡ã‚½ãƒƒãƒ‰ã®æ—¥æœ¬èªèª¬æ˜" }}
            - `Parameter`: ãƒ¡ã‚½ãƒƒãƒ‰ãŒå—ã‘å–ã‚‹å¼•æ•°ã€‚
                - `id`: `ãƒ¡ã‚½ãƒƒãƒ‰å_å¼•æ•°å` (ä¾‹: "CreateVariable_VariableName")
                - `properties`: {{ "name": "å¼•æ•°å", "description": "å¼•æ•°ã®èª¬æ˜", "order": å¼•æ•°ã®é †ç•ª(0ã‹ã‚‰) }}
            - `ReturnValue`: ãƒ¡ã‚½ãƒƒãƒ‰ã®æˆ»ã‚Šå€¤ã€‚
                - `id`: `ãƒ¡ã‚½ãƒƒãƒ‰å_ReturnValue` (ä¾‹: "CreateVariable_ReturnValue")
                - `properties`: {{ "description": "æˆ»ã‚Šå€¤ã®èª¬æ˜" }}
            - `DataType`: å¼•æ•°ã‚„æˆ»ã‚Šå€¤ã€å±æ€§ã®å‹ã€‚
                - `id`: ãƒ‡ãƒ¼ã‚¿å‹å (ä¾‹: "æ–‡å­—åˆ—", "é•·ã•", "bool", "ãƒ–ãƒ©ã‚±ãƒƒãƒˆè¦ç´ ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ", "æ•´æ•°")
                - `properties`: {{ "name": "ãƒ‡ãƒ¼ã‚¿å‹å" }} # èª¬æ˜ã¯å¾Œã§åˆ¥ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ä»˜ä¸ã—ã¾ã™
            - `Attribute`: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒæŒã¤å±æ€§ã€‚
                - `id`: `ãƒ‡ãƒ¼ã‚¿å‹å_å±æ€§å` (ä¾‹: "ãƒ–ãƒ©ã‚±ãƒƒãƒˆè¦ç´ ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ_DefinitionType")
                - `properties`: {{ "name": "å±æ€§å", "description": "å±æ€§ã®æ—¥æœ¬èªèª¬æ˜ (å‹æƒ…å ±ã‚’é™¤ã„ãŸã‚‚ã®)" }}

        2.  **ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ç¨®é¡:**
            - `BELONGS_TO`: (Method) -> (Object)
            - `HAS_PARAMETER`: (Method) -> (Parameter)
            - `HAS_RETURNS`: (Method) -> (ReturnValue)
            - `HAS_TYPE`: (Parameter) -> (DataType), (ReturnValue) -> (DataType), (Attribute) -> (DataType)
            - `HAS_ATTRIBUTE`: (DataType) -> (Attribute)
        
        --- æŠ½å‡ºãƒ«ãƒ¼ãƒ« ---
        1.  `â– ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå` ã¯ `Object` ãƒãƒ¼ãƒ‰ã¨ã—ã€å¾Œç¶šã® `Method` ã¯ `BELONGS_TO` ã§æ¥ç¶šã—ã¦ãã ã•ã„ã€‚
        2.  `ã€‡ã€‡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ` ã¨ã„ã†ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ `DataType` ãƒãƒ¼ãƒ‰ã¨ã—ã¦ãã ã•ã„ã€‚
        3.  ä¸Šè¨˜ `DataType` ã«ç¶šã `å±æ€§` (ä¾‹: `DefinitionType //sæ•´æ•°: ...`) ã¯ `Attribute` ãƒãƒ¼ãƒ‰ (`id: DataType_Attr`) ã¨ã—ã€`DataType` ã« `HAS_ATTRIBUTE` ã§æ¥ç¶šã—ã¦ãã ã•ã„ã€‚
        4.  `Attribute` ã® `description` ã«ã¯å‹æƒ…å ± (ä¾‹: `æ•´æ•°:`, `æ–‡å­—åˆ—ï¼š`) ã‚’ *é™¤ã„ãŸ* èª¬æ˜æ–‡ (ä¾‹: "ãƒ–ãƒ©ã‚±ãƒƒãƒˆã®ä½œæˆæ–¹æ³•æŒ‡å®š...") ã‚’æ ¼ç´ã—ã¦ãã ã•ã„ã€‚
        5.  `//` ã®å¾Œã®èª¬æ˜æ–‡ã«å‹æƒ…å ± (ä¾‹: `æ•´æ•°:`) ãŒå«ã¾ã‚Œã‚‹å ´åˆã€(Attribute)ã‹ã‚‰è©²å½“`DataType` (ä¾‹: "æ•´æ•°") ã¸ `HAS_TYPE` ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å¼µã£ã¦ãã ã•ã„ã€‚
        6.  `Create[... ]Param` (ä¾‹: `CreateBracketParam`) ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€å¯¾å¿œã™ã‚‹ `ã€‡ã€‡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ` (ä¾‹: "ãƒ–ãƒ©ã‚±ãƒƒãƒˆè¦ç´ ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ") ã‚’ `DataType` ã¨ã™ã‚‹ `ReturnValue` ã‚’æŒã¤ `Method` ã¨ã—ã¦æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
        7.  Parameterãƒãƒ¼ãƒ‰ã®descriptionã«ã¯ã€`ï¼š`ã®å¾Œã®æ–‡ç« ã‚’ãã®ã¾ã¾æŒ‡å®šã—ã¦ãã ã•ã„ã€‚

        --- å‡ºåŠ›å½¢å¼ ---
        - å…¨ä½“ã‚’1ã¤ã®JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        - **`nodes`** ã®å€¤ã¯ã€ä»¥ä¸‹ã®å½¢å¼ã®**ãƒãƒ¼ãƒ‰ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ**ã®ãƒªã‚¹ãƒˆã§ã™:
        `{{"id": "ä¸€æ„ã®ID", "type": "ãƒãƒ¼ãƒ‰ã®ç¨®é¡", "properties": {{...}} }}`
        - **`relationships`** ã®å€¤ã¯ã€ä»¥ä¸‹ã®å½¢å¼ã®**ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ**ã®ãƒªã‚¹ãƒˆã§ã™:
        `{{"source": "ã‚½ãƒ¼ã‚¹ãƒãƒ¼ãƒ‰ID", "target": "ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒãƒ¼ãƒ‰ID", "type": "ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ç¨®é¡"}}`

        --- APIä»•æ§˜æ›¸ãƒ†ã‚­ã‚¹ãƒˆ ---
        {raw_text}
        --- ã“ã“ã¾ã§ ---

        æŠ½å‡ºå¾Œã®JSON:
    """
    try:
        response = llm.invoke(prompt)
        # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‹ã‚‰JSONéƒ¨åˆ†ã‚’æŠ½å‡º
        match = re.search(r"```json\s*([\s\S]+?)\s*```", response.content)
        if match:
            json_str = match.group(1)
            return json.loads(json_str)
        else:
            # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ãŒãªã„å ´åˆã€ç›´æ¥ãƒ‘ãƒ¼ã‚¹ã‚’è©¦ã¿ã‚‹
            return json.loads(response.content)
    except Exception as e:
        print(f"      âš  LLMã«ã‚ˆã‚‹ã‚°ãƒ©ãƒ•æŠ½å‡ºã¾ãŸã¯JSONãƒ‘ãƒ¼ã‚¹ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return {"nodes": [], "relationships": []}

def _extract_datatype_descriptions_with_llm(raw_text: str) -> Dict[str, str]:
    """LLMã‚’ä½¿ã£ã¦api_arg.txtã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å‹ã®èª¬æ˜ã‚’æŠ½å‡ºã—ã€è¾æ›¸å½¢å¼ã§è¿”ã™"""
    prompt = f"""
    ã‚ãªãŸã¯APIä»•æ§˜æ›¸ã®ãƒ‡ãƒ¼ã‚¿å‹å®šç¾©ã‚’è§£æã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚
    ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€ãƒ‡ãƒ¼ã‚¿å‹ã¨ãã®èª¬æ˜æ–‡ã‚’æŠ½å‡ºã—ã€JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

    --- è§£æãƒ«ãƒ¼ãƒ« ---
    1.  `â– ` (U+25A0) ã§å§‹ã¾ã‚‹è¡Œã¯ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿å‹ã®å®šç¾©é–‹å§‹ã‚’ç¤ºã—ã¾ã™ã€‚
    2.  `â– ` ã®å¾Œã«ç¶šããƒ†ã‚­ã‚¹ãƒˆãŒã€Œãƒ‡ãƒ¼ã‚¿å‹åã€ã§ã™ (ä¾‹: `â– æ–‡å­—åˆ—` -> "æ–‡å­—åˆ—")ã€‚
    3.  ãƒ‡ãƒ¼ã‚¿å‹åã®æ¬¡ã®è¡Œã‹ã‚‰ã€æ¬¡ã® `â– ` ãŒå‡ºç¾ã™ã‚‹ç›´å‰ã¾ã§ã€ã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ«ã®çµ‚ã‚ã‚Šã¾ã§ãŒã€ãã®ãƒ‡ãƒ¼ã‚¿å‹ã®ã€Œèª¬æ˜æ–‡ã€ã§ã™ã€‚
    4.  èª¬æ˜æ–‡ã¯ã€æ”¹è¡Œã‚’å«ã‚ã¦ãã®ã¾ã¾é€£çµã—ã¦ãã ã•ã„ã€‚

    --- å‡ºåŠ›å½¢å¼ ---
    - å…¨ä½“ã‚’1ã¤ã®JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
    - ã‚­ãƒ¼ã‚’ã€Œãƒ‡ãƒ¼ã‚¿å‹åã€ã€å€¤ã‚’ã€Œèª¬æ˜æ–‡ã€ã¨ã—ãŸè¾æ›¸(ãƒãƒƒãƒ—)å½¢å¼ã¨ã—ã¾ã™ã€‚
    - ä¾‹: {{"æ–‡å­—åˆ—": "é€šå¸¸ã®æ–‡å­—åˆ—", "æµ®å‹•å°æ•°ç‚¹": "é€šå¸¸ã®æ•°å€¤\n\nä¾‹: 3.14"}}
    - JSONã¯ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯(` ```json ... ``` `)ã§å›²ã‚“ã§ãã ã•ã„ã€‚
    - JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ã¯ã‚³ãƒ¡ãƒ³ãƒˆã‚’ã„ã‚Œãªã„ã§ãã ã•ã„ã€‚
    - å¿…ãšJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

    --- ãƒ‡ãƒ¼ã‚¿å‹å®šç¾©ãƒ†ã‚­ã‚¹ãƒˆ ---
    {raw_text}
    --- ã“ã“ã¾ã§ ---

    æŠ½å‡ºå¾Œã®JSON:
    """
    try:
        response = llm.invoke(prompt)
        # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‹ã‚‰JSONéƒ¨åˆ†ã‚’æŠ½å‡º
        match = re.search(r"```json\s*([\s\S]+?)\s*```", response.content)
        if match:
            json_str = match.group(1)
            return json.loads(json_str)
        else:
            # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ãŒãªã„å ´åˆã€ç›´æ¥ãƒ‘ãƒ¼ã‚¹ã‚’è©¦ã¿ã‚‹
            return json.loads(response.content)
    except Exception as e:
        print(f"      âš  LLMã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿å‹èª¬æ˜ã®æŠ½å‡ºã¾ãŸã¯JSONãƒ‘ãƒ¼ã‚¹ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return {}

def extract_triples_from_specs(
    graph_data: Dict[str, List[Dict[str, Any]]], 
    type_descriptions: Dict[str, str]
    ) -> Tuple[List[Dict[str, Any]], Dict[str, Dict[str, Any]]]:
    """LLMãŒæŠ½å‡ºã—ãŸã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€å¾Œç¶šå‡¦ç†ã§åˆ©ç”¨ã™ã‚‹ãƒˆãƒªãƒ—ãƒ«å½¢å¼ã‚’ç”Ÿæˆã™ã‚‹"""
    
    triples: List[Dict[str, Any]] = []
    node_props: Dict[str, Dict[str, Any]] = {}
    
    nodes = graph_data.get("nodes", [])
    relationships = graph_data.get("relationships", [])
    
    node_type_map = {}

    # 1. ãƒãƒ¼ãƒ‰æƒ…å ±ã‚’ node_props ã¨ node_type_map ã«æ ¼ç´
    for node in nodes:
        node_id = node["id"]
        node_type = node["type"]
        properties = node.get("properties", {})
        
        # DataTypeãƒãƒ¼ãƒ‰ã¸ã®èª¬æ˜è¿½åŠ ã¯å‘¼ã³å‡ºã—å…ƒã§è¡Œã†
        # if node_type == "DataType" and properties.get("name") in type_descriptions:
        #     properties["description"] = type_descriptions[properties["name"]]

        node_props[node_id] = {"type": node_type, "properties": properties}
        node_type_map[node_id] = node_type

    # 2. ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±ã‹ã‚‰ãƒˆãƒªãƒ—ãƒ«ã‚’ç”Ÿæˆ
    for rel in relationships:
        source_id = rel["source"]
        target_id = rel["target"]
        
        # ãƒãƒƒãƒ—ã«å­˜åœ¨ã—ãªã„ãƒãƒ¼ãƒ‰IDã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if source_id not in node_type_map or target_id not in node_type_map:
            continue
            
        triples.append({
            "source": source_id,
            "source_type": node_type_map[source_id],
            "label": rel["type"],
            "target": target_id,
            "target_type": node_type_map[target_id],
        })
        
    return triples, node_props


def _extract_method_calls_from_script(script_text: str) -> List[Dict[str, Any]]:
    """
    ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ†ã‚­ã‚¹ãƒˆã‚’è§£æã—ã€ãƒ¡ã‚½ãƒƒãƒ‰å‘¼ã³å‡ºã—ã®è©³ç´°æƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹ã€‚
    ææ¡ˆ1ã®å®Ÿè£…ï¼šãƒ¡ã‚½ãƒƒãƒ‰å‘¼ã³å‡ºã—ã®çµæœãŒä»£å…¥ã•ã‚Œã‚‹å¤‰æ•°åã‚‚å–å¾—ã™ã‚‹ã€‚
    """
    tree = parser.parse(bytes(script_text, "utf8"))
    root_node = tree.root_node
    calls = []
    
    def find_calls(node):
        # ãƒ¡ã‚½ãƒƒãƒ‰å‘¼ã³å‡ºã— (`call`ãƒãƒ¼ãƒ‰) ã‚’æ¢ã™
        if node.type == 'call':
            function_node = node.child_by_field_name('function')
            # obj.method() ã®å½¢å¼ (`attribute`ãƒãƒ¼ãƒ‰) ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
            if function_node and function_node.type == 'attribute':
                obj_node = function_node.child_by_field_name('object')
                method_node = function_node.child_by_field_name('attribute')
                
                if obj_node and method_node:
                    call_details = {
                        "object_name": obj_node.text.decode('utf8'),
                        "method_name": method_node.text.decode('utf8'),
                        "full_text": node.text.decode('utf8'),
                        "node": node,  # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼è§£æã®ãŸã‚ã«nodeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆè‡ªä½“ã‚’ä¿æŒ
                        "assigned_to": None, # çµæœãŒä»£å…¥ã•ã‚Œã‚‹å¤‰æ•°åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯Noneï¼‰
                    }
                    
                    # ã“ã®å‘¼ã³å‡ºã—ãŒä»£å…¥æ–‡ã®ä¸€éƒ¨ã‹ãƒã‚§ãƒƒã‚¯ (e.g., var = obj.method())
                    parent = node.parent
                    if parent and parent.type == 'assignment':
                        left_node = parent.child_by_field_name('left')
                        if left_node:
                            call_details["assigned_to"] = left_node.text.decode('utf8')
                            
                    calls.append(call_details)

        # å†å¸°çš„ã«å­ãƒãƒ¼ãƒ‰ã‚’æ¢ç´¢
        for child in node.children:
            find_calls(child)

    find_calls(root_node)
    return calls


def _triples_to_graph_documents(triples: List[Dict[str, Any]], node_props: Dict[str, Dict[str, Any]]) -> List[GraphDocument]:
    node_map: Dict[str, Node] = {}
    for node_id, meta in node_props.items():
        if node_id in node_map:
            existing_node = node_map[node_id]
            existing_node.properties.update(meta.get("properties", {}))
        else:
            ntype = meta["type"]
            props = meta.get("properties", {})
            node_map[node_id] = Node(id=node_id, type=ntype, properties=props)

    rels: List[Relationship] = []
    for t in triples:
        source_node = node_map.get(t["source"])
        if not source_node:
            source_node = Node(id=t["source"], type=t["source_type"])
            node_map[t["source"]] = source_node

        target_node = node_map.get(t["target"])
        if not target_node:
            target_node = Node(id=t["target"], type=t["target_type"])
            node_map[t["target"]] = target_node

        rels.append(
            Relationship(
                source=source_node,
                target=target_node,
                type=t["label"],
                properties={}
            )
        )

    doc = Document(page_content="API Spec and Example graph")
    gdoc = GraphDocument(nodes=list(node_map.values()), relationships=rels, source=doc)
    return [gdoc]

def _rebuild_graph_in_neo4j(graph_docs: List[GraphDocument]) -> Tuple[int, int]:
    graph = Neo4jGraph(
        url=NEO4J_URI,
        username=NEO4J_USER,
        password=NEO4J_PASSWORD,
        database=NEO4J_DATABASE,
    )
    
    print("ğŸ§¹ Neo4jã®æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ä¸­...")
    delete_query = "MATCH (n) DETACH DELETE n"
    graph.query(delete_query)
    
    print(f"\nğŸš€ Neo4jã«ãƒ‡ãƒ¼ã‚¿ã‚’æŠ•å…¥ä¸­...")
    
    graph.add_graph_documents(graph_docs)
    
    res_nodes = graph.query("MATCH (n) RETURN count(n) AS c")
    res_rels = graph.query("MATCH ()-[r]->() RETURN count(r) AS c")
    return int(res_nodes[0]["c"]), int(res_rels[0]["c"])

def _build_and_load_chroma(
    triples: List[Dict[str, Any]], 
    node_props: Dict[str, Dict[str, Any]]
    ) -> None:
    """
    triples (ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®šç¾©) ã¨ node_props (ãƒãƒ¼ãƒ‰å®šç¾©) ã‚’å—ã‘å–ã‚Šã€
    ãã‚Œã‚‰ã‚’ãã®ã¾ã¾ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦ChromaDBã«ä¿å­˜ã™ã‚‹ã€‚
    """
    print("\nğŸš€ ChromaDBã®ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆãƒ»ä¿å­˜ä¸­...")

    if CHROMA_PERSIST_DIR.exists():
        shutil.rmtree(CHROMA_PERSIST_DIR)
    CHROMA_PERSIST_DIR.mkdir(exist_ok=True)

    docs_for_vectorstore: List[Document] = []
    
    if not node_props and not triples:
        print("âš  ãƒ‡ãƒ¼ã‚¿(node_props/triples)ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ChromaDBã®æ§‹ç¯‰ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return

    # 1. ãƒãƒ¼ãƒ‰ã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–
    # node_props = { "NodeID": { "type": "Type", "properties": {...} }, ... }
    print(f"âœ” {len(node_props)} å€‹ã®ãƒãƒ¼ãƒ‰å®šç¾©ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã®å¯¾è±¡ã¨ã—ã¾ã™ã€‚")
    for node_id, meta in node_props.items():
        node_type = meta.get("type", "Unknown")
        properties = meta.get("properties", {})
        
        # ãƒãƒ¼ãƒ‰æƒ…å ±ã‚’æ–‡å­—åˆ—åŒ–
        content = f"Node ID: {node_id}\nNode Type: {node_type}\nProperties: {json.dumps(properties, ensure_ascii=False)}"
        
        metadata = {
            "source": "graph_node",
            "node_id": node_id,
            "node_type": node_type,
        }
        docs_for_vectorstore.append(Document(page_content=content, metadata=metadata))

    # 2. ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–
    # triples = [ {"source": "ID", "source_type": "Type", "label": "REL", "target": "ID", "target_type": "Type"}, ... ]
    print(f"âœ” {len(triples)} å€‹ã®ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®šç¾©ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã®å¯¾è±¡ã¨ã—ã¾ã™ã€‚")
    for rel in triples:
        source_id = rel.get("source")
        target_id = rel.get("target")
        rel_type = rel.get("label")
        
        # ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡¨ã™ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
        content = f"Relationship: {source_id} -[{rel_type}]-> {target_id}"
        
        metadata = {
            "source": "graph_relationship",
            "source_node": source_id,
            "target_node": target_id,
            "relation_type": rel_type,
        }
        docs_for_vectorstore.append(Document(page_content=content, metadata=metadata))

    # ChromaDBã«æŠ•å…¥ã™ã‚‹å‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
    chroma_data_to_save = [
        {"page_content": doc.page_content, "metadata": doc.metadata}
        for doc in docs_for_vectorstore
    ]
    with open("chroma_data.json", "w", encoding="utf-8") as f:
        json.dump(chroma_data_to_save, f, indent=2, ensure_ascii=False)
    print("ğŸ’¾ ChromaDBæŠ•å…¥å‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’ 'chroma_data.json' ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")

    try:
        embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
        vectorstore = Chroma.from_documents(
            documents=docs_for_vectorstore,
            embedding=embeddings,
            persist_directory=str(CHROMA_PERSIST_DIR),
        )
        print(f"âœ” Chroma DB created and persisted with {len(docs_for_vectorstore)} documents at: {CHROMA_PERSIST_DIR}")
    except Exception as e:
        print(f"âš  Chroma DBã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        
def _build_and_load_neo4j() -> Tuple[List[GraphDocument], List[Dict[str, Any]], Dict[str, Dict[str, Any]]]:
    """
    APIä»•æ§˜ã¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹ã‚’è§£æã—ã€Neo4jã«ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚
    
    Returns:
        Tuple containing:
        1. gdocs (Neo4jæŒ¿å…¥ç”¨)
        2. all_triples (ChromaDBæŒ¿å…¥ç”¨ã®ç”Ÿãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿)
        3. all_node_props (ChromaDBæŒ¿å…¥ç”¨ã®ç”Ÿãƒãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿)
    """
    # --- 1. APIä»•æ§˜æ›¸ (api*.txt, api_arg.txt) ã®è§£æ ---
    print("ğŸ“„ APIä»•æ§˜æ›¸ã‚’è§£æä¸­...")

    # 4ã¤ã®APIä»•æ§˜æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®šç¾©
    api_txt_files = [
        DATA_DIR / "api1.txt",
        DATA_DIR / "api2.txt",
        DATA_DIR / "api3.txt",
        DATA_DIR / "api4.txt",
        DATA_DIR / "api5.txt",
    ]
    
    all_nodes = []
    all_relationships = []
    
    # LLMã§APIä»•æ§˜æ›¸ã‹ã‚‰ç›´æ¥ã‚°ãƒ©ãƒ•æ§‹é€ (ãƒãƒ¼ãƒ‰/ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³)ã‚’æŠ½å‡º
    print("ğŸ¤– LLMã«ã‚ˆã‚‹APIä»•æ§˜æ›¸ã‹ã‚‰ã®ã‚°ãƒ©ãƒ•æŠ½å‡ºã‚’å®Ÿè¡Œä¸­...")
    
    for api_file_path in api_txt_files:
        if not api_file_path.exists():
            print(f"âš  è­¦å‘Š: {api_file_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            continue
        
        print(f"  - ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æä¸­: {api_file_path.name}")
        try:
            api_text = api_file_path.read_text(encoding="utf-8")
            # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            partial_api_data = _extract_graph_from_specs_with_llm(api_text)
            
            nodes = partial_api_data.get("nodes", [])
            rels = partial_api_data.get("relationships", [])
            
            print(f"    -> æŠ½å‡ºçµæœ: ãƒãƒ¼ãƒ‰={len(nodes)}ä»¶, ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³={len(rels)}ä»¶")
            
            all_nodes.extend(nodes)
            all_relationships.extend(rels)
            
        except FileNotFoundError:
            print(f"âš  è­¦å‘Š: {api_file_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        except Exception as e:
            print(f"âš  {api_file_path.name} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    # æŠ½å‡ºã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ
    # é‡è¤‡ãƒãƒ¼ãƒ‰ã‚’IDã«åŸºã¥ã„ã¦ãƒãƒ¼ã‚¸ã™ã‚‹ï¼ˆå¾Œå‹ã¡ï¼‰
    merged_nodes_dict = {}
    for node in all_nodes:
        node_id = node.get("id")
        if node_id:
            if node_id in merged_nodes_dict:
                # æ—¢å­˜ã®ãƒãƒ¼ãƒ‰ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’æ›´æ–°ï¼ˆãƒãƒ¼ã‚¸ï¼‰
                merged_nodes_dict[node_id].setdefault("properties", {}).update(node.get("properties", {}))
            else:
                merged_nodes_dict[node_id] = node
    
    merged_nodes = list(merged_nodes_dict.values())
    
    # é‡è¤‡ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆsource, target, typeãŒåŒä¸€ï¼‰ã‚’å‰Šé™¤
    seen_rels = set()
    merged_relationships = []
    for rel in all_relationships:
        rel_tuple = (rel.get("source"), rel.get("target"), rel.get("type"))
        if rel.get("source") and rel.get("target") and rel.get("type") and rel_tuple not in seen_rels:
            merged_relationships.append(rel)
            seen_rels.add(rel_tuple)

    api_data_from_llm = {
        "nodes": merged_nodes,
        "relationships": merged_relationships
    }
    
    print(f"âœ” çµ±åˆå¾Œã®APIä»•æ§˜æ›¸ãƒ‡ãƒ¼ã‚¿: ãƒãƒ¼ãƒ‰={len(merged_nodes)}ä»¶, ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³={len(merged_relationships)}ä»¶")
    
    # ãƒ‡ãƒ¼ã‚¿å‹ã®èª¬æ˜ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿è¾¼ã‚€ 
    api_arg_text = _read_api_arg_text()
    print("ğŸ¤– LLMã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿å‹èª¬æ˜ (api_arg.txt) ã®æŠ½å‡ºã‚’å®Ÿè¡Œä¸­...")
    type_descriptions = _extract_datatype_descriptions_with_llm(api_arg_text)
    
    # LLMãŒç”Ÿæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã«ãƒ‡ãƒ¼ã‚¿å‹ã®èª¬æ˜ã‚’è¿½åŠ 
    for node in api_data_from_llm.get("nodes", []):
        if node.get("type") == "DataType" and node.get("properties", {}).get("name") in type_descriptions:
            node["properties"]["description"] = type_descriptions[node["properties"]["name"]]

    # LLMã®å‡ºåŠ›ã‚’å¾Œç¶šå‡¦ç†ç”¨ã®ãƒˆãƒªãƒ—ãƒ«å½¢å¼ã«å¤‰æ›
    spec_triples, spec_node_props = extract_triples_from_specs(api_data_from_llm, type_descriptions)
    
    print(f"âœ” APIä»•æ§˜æ›¸ã‹ã‚‰ãƒˆãƒªãƒ—ãƒ«ã‚’ç”Ÿæˆ: {len(spec_triples)} ä»¶")

    # Neo4jã«æŠ•å…¥ã™ã‚‹å‰ã®APIä»•æ§˜æ›¸ç”±æ¥ã®ãƒ‡ãƒ¼ã‚¿(ãƒˆãƒªãƒ—ãƒ«ã¨ãƒãƒ¼ãƒ‰ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£)ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
    data_to_save = {
        "relationships": spec_triples,
        "nodes": spec_node_props
    }
    with open("neo4j_data.json", "w", encoding="utf-8") as f:
        json.dump(
            data_to_save,
            f,
            indent=2,
            ensure_ascii=False,
        )
    print("ğŸ’¾ APIä»•æ§˜æ›¸è§£æå¾Œã®ãƒ‡ãƒ¼ã‚¿(ãƒˆãƒªãƒ—ãƒ«/ãƒãƒ¼ãƒ‰)ã‚’ 'neo4j_data.json' ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")

    # --- 2. ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹ (data/*.py) ã®è§£æ ---
    print("\nğŸ ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹ (data/*.py) ã‚’è§£æä¸­...")
    script_files = _read_script_files()
    if not script_files:
        print("âš  data ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«è§£æå¯¾è±¡ã® .py ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        script_triples, script_node_props = [], {}
    else:
        all_script_triples = []
        all_script_node_props = {}
        for script_path, script_text in script_files:
            print(f"  - ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æä¸­: {script_path}")
            triples, node_props = extract_triples_from_script(script_path, script_text)
            all_script_triples.extend(triples)
            all_script_node_props.update(node_props)
        script_triples = all_script_triples
        script_node_props = all_script_node_props
        print(f"âœ” ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹ã‹ã‚‰ãƒˆãƒªãƒ—ãƒ«ã‚’ç·è¨ˆ: {len(script_triples)} ä»¶")

    # --- 3. ãƒ‡ãƒ¼ã‚¿ã®çµ±åˆã¨ã‚°ãƒ©ãƒ•DBã¸ã®æŠ•å…¥ ---
    print("\nğŸ”— ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã¦ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰ä¸­...")
    
    # Chromaç”¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’ã¾ã¨ã‚ã‚‹
    all_triples = spec_triples + script_triples
    all_node_props = {**spec_node_props, **script_node_props}
    
    # Neo4jç”¨ã®GraphDocumentã‚’ç”Ÿæˆ
    gdocs = _triples_to_graph_documents(all_triples, all_node_props)
    
    try:
        node_count, rel_count = _rebuild_graph_in_neo4j(gdocs)
        print(f"âœ” ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å†æ§‹ç¯‰ãŒå®Œäº†ã—ã¾ã—ãŸ: ãƒãƒ¼ãƒ‰={node_count}, ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ãƒƒãƒ—={rel_count}")
    except ServiceUnavailable as se:
        print(f"âš  Neo4j ã¸ã®æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ: {se}")
        print("   Neo4jã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    except Exception as e:
        print(f"âš  ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ§‹ç¯‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    # gdocsã ã‘ã§ãªãã€ç”Ÿã®triplesã¨node_propsã‚‚è¿”ã™
    return gdocs, all_triples, all_node_props

def main() -> None:
    # --- Neo4jæ§‹ç¯‰ãƒ—ãƒ­ã‚»ã‚¹ ---
    # Neo4jã‚’æ§‹ç¯‰ã—ã€ãã®éç¨‹ã§ç”Ÿæˆã•ã‚ŒãŸç”Ÿã®triplesã¨node_propsã‚‚å—ã‘å–ã‚‹
    _, all_triples, all_node_props = _build_and_load_neo4j()

    # --- ChromaDBæ§‹ç¯‰ãƒ—ãƒ­ã‚»ã‚¹ ---
    # gdocsã§ã¯ãªãã€ç”Ÿã®triplesã¨node_propsã‚’æ¸¡ã—ã¦ChromaDBã‚’æ§‹ç¯‰ã™ã‚‹
    _build_and_load_chroma(all_triples, all_node_props)

if __name__ == "__main__":
    main()