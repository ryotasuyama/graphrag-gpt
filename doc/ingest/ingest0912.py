from pathlib import Path
import re
import shutil
from typing import List, Tuple, Dict, Any

import config
from langchain_core.documents import Document
from langchain_neo4j import Neo4jGraph
from neo4j.exceptions import ServiceUnavailable
from langchain_community.graphs.graph_document import GraphDocument
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_experimental.graph_transformers import LLMGraphTransformer

# --- å®šæ•°å®šç¾© (å¤‰æ›´ãªã—) ---
DATA_DIR = Path("data")
NEO4J_URI = config.NEO4J_URI
NEO4J_USER = config.NEO4J_USER
NEO4J_PASSWORD = config.NEO4J_PASSWORD
NEO4J_DATABASE = getattr(config, "NEO4J_DATABASE", "neo4j")

API_TXT_CANDIDATES = [
    Path("/mnt/data/api.txt"),
    Path("api.txt"),
    DATA_DIR / "api.txt",
]

API_ARG_TXT_CANDIDATES = [
    Path("/mnt/data/api_arg.txt"),
    Path("api_arg.txt"),
    DATA_DIR / "api_arg.txt",
]

CHROMA_PERSIST_DIR = DATA_DIR / "chroma_db"
OPENAI_API_KEY = config.OPENAI_API_KEY

# --- ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ãƒ»ãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–é–¢æ•° (å¤‰æ›´ãªã—) ---

def _read_api_text() -> str:
    """api.txt ã‚’å€™è£œãƒ‘ã‚¹ã‹ã‚‰èª­ã¿è¾¼ã‚€"""
    for p in API_TXT_CANDIDATES:
        if p.exists():
            return p.read_text(encoding="utf-8")
    raise FileNotFoundError("api.txt ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚/mnt/data/api.txt ã¾ãŸã¯ ./api.txt ã‚’ç”¨æ„ã—ã¦ãã ã•ã„ã€‚")

def _read_api_arg_text() -> str:
    """api_arg.txt ã‚’å€™è£œãƒ‘ã‚¹ã‹ã‚‰èª­ã¿è¾¼ã‚€"""
    for p in API_ARG_TXT_CANDIDATES:
        if p.exists():
            return p.read_text(encoding="utf-8")
    raise FileNotFoundError("api_arg.txt ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

def _read_script_files() -> List[Tuple[str, str]]:
    """data ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã® .py ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã™ã¹ã¦èª­ã¿è¾¼ã‚€"""
    script_files = []
    if not DATA_DIR.exists():
        return []
    
    for p in DATA_DIR.glob("*.py"):
        if p.is_file():
            script_files.append((p.name, p.read_text(encoding="utf-8")))
            
    return script_files

def _normalize_text(text: str) -> str:
    """
    æ”¹è¡Œ/ã‚¿ãƒ–/ç©ºç™½ã®æºã‚Œã‚’æ­£è¦åŒ–ã€‚
    """
    text = text.replace("\ufeff", "")
    text = text.replace("\r\n", "\n").replace("\r", "\n")
    text = "\n".join(line.rstrip() for line in text.split("\n"))
    text = text.replace("\t", " ")
    text = re.sub(r"[ \u00A0\u3000]+", " ", text)
    return text

# --- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œé–¢æ•° (å¤‰æ›´ãªã—) ---

def _rebuild_graph_in_neo4j(graph_docs: List[GraphDocument]) -> Tuple[int, int]:
    """
    Neo4j ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦ã‹ã‚‰ GraphDocument ã‚’æŠ•å…¥ã™ã‚‹
    """
    graph = Neo4jGraph(
        url=NEO4J_URI,
        username=NEO4J_USER,
        password=NEO4J_PASSWORD,
        database=NEO4J_DATABASE,
    )
    
    print("ğŸ§¹ Neo4jã®æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ä¸­...")
    delete_query = "MATCH (n) DETACH DELETE n"
    graph.query(delete_query)
    
    print(f"\nğŸš€ Neo4jã«ãƒ‡ãƒ¼ã‚¿ã‚’æŠ•å…¥ä¸­...")
    
    graph.add_graph_documents(graph_docs)
    
    res_nodes = graph.query("MATCH (n) RETURN count(n) AS c")
    res_rels = graph.query("MATCH ()-[r]->() RETURN count(r) AS c")
    return int(res_nodes[0]["c"]), int(res_rels[0]["c"])

# --- ChromaDBæ§‹ç¯‰é–¢æ•° (ä¿®æ­£) ---

def _build_and_load_chroma(docs_for_vectorstore: List[Document]) -> None:
    """
    ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒªã‚¹ãƒˆã‹ã‚‰ãƒ™ã‚¯ãƒˆãƒ«DB (Chroma) ã‚’æ§‹ç¯‰ãƒ»æ°¸ç¶šåŒ–ã™ã‚‹
    """
    print("\nğŸš€ ChromaDBã®ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆãƒ»ä¿å­˜ä¸­...")

    if CHROMA_PERSIST_DIR.exists():
        shutil.rmtree(CHROMA_PERSIST_DIR)
    CHROMA_PERSIST_DIR.mkdir(exist_ok=True)

    try:
        embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
        vectorstore = Chroma.from_documents(
            documents=docs_for_vectorstore,
            embedding=embeddings,
            persist_directory=str(CHROMA_PERSIST_DIR),
        )
        print(
            f"âœ” Chroma DB created and persisted with {len(docs_for_vectorstore)} documents at: {CHROMA_PERSIST_DIR}"
        )
    except Exception as e:
        print(f"âš  Chroma DBã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

# --- Neo4jã‚°ãƒ©ãƒ•æ§‹ç¯‰é–¢æ•° (ä¿®æ­£) ---

def _build_and_load_neo4j() -> None:
    """
    LLMGraphTransformerã‚’ä½¿ç”¨ã—ã¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰ã—ã€Neo4jã«ãƒ­ãƒ¼ãƒ‰ã™ã‚‹
    """
    # --- 1. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®èª­ã¿è¾¼ã¿ ---
    print("ğŸ“„ APIä»•æ§˜æ›¸ã¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    api_text = _normalize_text(_read_api_text())
    api_arg_text = _normalize_text(_read_api_arg_text())
    script_files = _read_script_files()
    
    # LangChain Documentã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
    documents = [
        Document(page_content=api_text, metadata={"source": "api.txt"}),
        Document(page_content=api_arg_text, metadata={"source": "api_arg.txt"})
    ]
    for script_name, script_content in script_files:
        documents.append(Document(page_content=script_content, metadata={"source": script_name}))
    
    print(f"âœ” åˆè¨ˆ {len(documents)} ä»¶ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‡¦ç†å¯¾è±¡ã¨ã—ã¾ã™ã€‚")

    # --- 2. LLMã«ã‚ˆã‚‹ã‚°ãƒ©ãƒ•æŠ½å‡º ---
    print("\nğŸ¤– LLMã‚’ä½¿ç”¨ã—ã¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºä¸­...")
    llm = ChatOpenAI(temperature=1, model_name="gpt-5-mini", openai_api_key=OPENAI_API_KEY)
    llm_transformer = LLMGraphTransformer(llm=llm)

    gdocs = llm_transformer.convert_to_graph_documents(documents)
    print(f"âœ” LLMã«ã‚ˆã‚‹ã‚°ãƒ©ãƒ•æŠ½å‡ºãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

    # --- 3. Neo4jã¸ã®ãƒ‡ãƒ¼ã‚¿æŠ•å…¥ ---
    try:
        node_count, rel_count = _rebuild_graph_in_neo4j(gdocs)
        print(f"âœ” ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å†æ§‹ç¯‰ãŒå®Œäº†ã—ã¾ã—ãŸ: ãƒãƒ¼ãƒ‰={node_count}, ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ãƒƒãƒ—={rel_count}")
    except ServiceUnavailable as se:
        print(f"âš  Neo4j ã¸ã®æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ: {se}")
        print("   Neo4jã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ã€æ¥ç¶šæƒ…å ±ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    except Exception as e:
        print(f"âš  ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ§‹ç¯‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# --- mainé–¢æ•° (ä¿®æ­£) ---

def main() -> None:
    """
    ãƒ¡ã‚¤ãƒ³å‡¦ç†
    """
    # ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ (Neo4j) ã‚’æ§‹ç¯‰
    _build_and_load_neo4j()

    # ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ (Chroma) ã‚’æ§‹ç¯‰
    print("\n--- ChromaDBæ§‹ç¯‰ãƒ—ãƒ­ã‚»ã‚¹ ---")
    api_text = _read_api_text()
    script_files = _read_script_files()
    
    docs_for_vectorstore: List[Document] = []

    # 1. APIä»•æ§˜ã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆ
    content_api = _normalize_text(api_text)
    docs_for_vectorstore.append(Document(
        page_content=content_api, 
        metadata={"source": "api_spec"}
    ))
    print(f"âœ” APIä»•æ§˜æ›¸ã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’1ä»¶ä½œæˆã—ã¾ã—ãŸã€‚")
    
    # 2. ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹ã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆ
    if script_files:
        for script_name, script_content in script_files:
            content = (
                f"ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹: {script_name}\n\n```python\n{script_content}\n```"
            )
            metadata = {
                "source": "script_example",
                "script_name": script_name,
            }
            docs_for_vectorstore.append(Document(page_content=content, metadata=metadata))
        print(f"âœ” {len(script_files)}ä»¶ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹ã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆã—ã¾ã—ãŸã€‚")
    else:
        print("âš  ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    
    # æƒ…å ±ã‚’æ¸¡ã—ã¦ChromaDBã‚’æ§‹ç¯‰
    _build_and_load_chroma(docs_for_vectorstore)


if __name__ == "__main__":
    main()