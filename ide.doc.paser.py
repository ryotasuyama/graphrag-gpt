from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
import json
import os
import sys
import argparse
from typing import Dict, List, Any, Union, TypedDict
from langgraph.graph import StateGraph, END


# ===== å®šæ•°å®šç¾© =====
class Config:
    """è¨­å®šå®šæ•°ã‚¯ãƒ©ã‚¹"""

    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    DEFAULT_API_DOC_PATH = "data/src/api.txt"
    DEFAULT_API_ARG_PATH = "data/src/api_arg.txt"
    DEFAULT_OUTPUT_PATH = "doc_parser/parsed_api_result.json"
    DEFAULT_ENCODING = "utf-8"

    # ãƒ¢ãƒ‡ãƒ«è¨­å®š
    MODEL_CONFIG = {
        "model": "gpt-5-mini",  # "gpt-5-nano", "gpt-5-mini", "gpt-5"
        "output_version": "responses/v1",
        "reasoning_effort": "high",  # "minimal", 'low', 'medium', 'high'
        "verbosity": "high",  # 'low', 'medium', 'high'
    }

    # è‡ªå·±ä¿®æ­£è¨­å®š
    DEFAULT_MAX_CORRECTIONS = 3
    DEFAULT_QUALITY_THRESHOLD = 90.0
    QUALITY_PENALTY_PER_ISSUE = 20


# ===== çŠ¶æ…‹å®šç¾© =====
class SelfCorrectionState(TypedDict):
    """è‡ªå·±ä¿®æ­£ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çŠ¶æ…‹"""

    messages: List[Dict[str, Any]]
    current_code: str
    errors: List[Dict[str, Any]]
    corrections_made: int
    max_corrections: int
    correction_history: List[Dict[str, Any]]
    quality_score: float


# ===== åˆæœŸåŒ– =====
load_dotenv()


# ===== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° =====
def safe_file_operation(operation, *args, **kwargs):
    """ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œã®å®‰å…¨ãªå®Ÿè¡Œ"""
    try:
        return operation(*args, **kwargs)
    except FileNotFoundError as e:
        raise FileNotFoundError(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    except UnicodeDecodeError as e:
        raise e
    except PermissionError as e:
        raise PermissionError(f"ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“: {e}")
    except IOError as e:
        raise IOError(f"ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œã‚¨ãƒ©ãƒ¼: {e}")


def read_file_safely(file_path: str, encoding: str = Config.DEFAULT_ENCODING) -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®‰å…¨ã«èª­ã¿è¾¼ã‚€ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãï¼‰"""

    def read_operation():
        last_err: Exception | None = None
        for enc in (encoding, "utf-8-sig", "cp932", "shift_jis"):
            try:
                with open(file_path, "r", encoding=enc) as file:
                    return file.read()
            except UnicodeDecodeError as e:
                last_err = e
                continue
        # ã™ã¹ã¦å¤±æ•—ã—ãŸå ´åˆã¯æœ€å¾Œã®ã‚¨ãƒ©ãƒ¼ã‚’å†é€å‡º
        if last_err:
            raise last_err
        # æƒ³å®šå¤–ã®ã‚±ãƒ¼ã‚¹ï¼ˆç†è«–ä¸Šåˆ°é”ã—ãªã„ï¼‰
        with open(file_path, "r", encoding=encoding) as file:
            return file.read()

    return safe_file_operation(read_operation)


def write_file_safely(file_path: str, content: str, encoding: str = Config.DEFAULT_ENCODING) -> None:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®‰å…¨ã«æ›¸ãè¾¼ã‚€"""

    def write_operation():
        directory = os.path.dirname(file_path)
        if directory:
            os.makedirs(directory, exist_ok=True)
        with open(file_path, "w", encoding=encoding) as file:
            file.write(content)

    safe_file_operation(write_operation)


# ===== ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œé–¢æ•° =====
def load_api_document(api_doc_path: str = None, api_arg_path: str = None) -> str:
    """APIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨å¼•æ•°æƒ…å ±ã‚’é€£çµã—ã¦èª­ã¿è¾¼ã‚€"""
    api_doc_path = api_doc_path or Config.DEFAULT_API_DOC_PATH
    api_arg_path = api_arg_path or Config.DEFAULT_API_ARG_PATH

    try:
        api_doc_content = read_file_safely(api_doc_path)
        api_arg_content = read_file_safely(api_arg_path)

        return f"""
        # APIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

        {api_doc_content}

        ---

        # å¼•æ•°ã®å‹ã¨æ›¸å¼

        {api_arg_content}
        """
    except Exception as e:
        print(f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        raise


def save_parsed_result(parsed_result: Union[Dict, List], output_file_path: str = None) -> None:
    """è§£æçµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜"""
    output_file_path = output_file_path or Config.DEFAULT_OUTPUT_PATH

    try:
        json_content = json.dumps(parsed_result, ensure_ascii=False, indent=2)
        write_file_safely(output_file_path, json_content)
        print(f"è§£æçµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_file_path}")
    except Exception as e:
        print(f"è§£æçµæœã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        raise


# ===== ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç† =====
class PromptManager:
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    @staticmethod
    def get_system_prompt() -> str:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—ã™ã‚‹"""
        return """
        <prompt>
            <developer>
                <specialty>EVO.SHIP APIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æ­£ç¢ºãªè§£æ</specialty>
                <role>
                    ã‚ãªãŸã¯ã€ŒEVO.SHIP APIã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å³å¯†ã«è§£æã—ã€æŒ‡å®šã•ã‚ŒãŸJSONå½¢å¼ã§å‡ºåŠ›ã™ã‚‹å„ªç§€ãªã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚
                </role>
                <workflow>
                    <step>ã“ã‚Œã‹ã‚‰å–ã‚Šçµ„ã‚€ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã®ç°¡æ½”ãªãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã‚’æç¤ºã™ã‚‹</step>
                    <step>æä¾›ã•ã‚ŒãŸAPIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç²¾æŸ»ã™ã‚‹</step>
                    <step>è§£æçµæœã‚’å˜ä¸€ã®JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦å‡ºåŠ›ã™ã‚‹</step>
                    <note>ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã¯æœ€çµ‚å‡ºåŠ›JSONã®ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰checklistã¨ã—ã¦å«ã‚ã‚‹ã“ã¨</note>
                </workflow>
                <guidelines>
                    <general>
                        <item>å‡ºåŠ›ã¯æœ‰åŠ¹ãªJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã¿ã¨ã—ã€Markdownã‚„ãã®ä»–ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å«ã‚ãªã„</item>
                        <item>ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«è¨˜è¼‰ã•ã‚Œã¦ã„ãªã„æƒ…å ±ã®æ¨æ¸¬ã¯çµ¶å¯¾ã«è¡Œã‚ãªã„</item>
                        <item>è§£æå¯¾è±¡ã¯ã€ŒAPIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã€ã¨ã€Œå¼•æ•°ã®å‹ã¨æ›¸å¼ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³å…¨ä½“ã¨ã™ã‚‹</item>
                    </general>
                    <analysis_points>
                        <type_definitions>
                            <item>ã€Œå¼•æ•°ã®å‹ã¨æ›¸å¼ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰<strong>ã™ã¹ã¦ã®</strong>ãƒ‡ãƒ¼ã‚¿å‹ã‚’æ¼ã‚ŒãªãæŠ½å‡ºã™ã‚‹</item>
                            <item>åŸºæœ¬å‹ï¼ˆæ–‡å­—åˆ—ã€æµ®å‹•å°æ•°ç‚¹ã€æ•´æ•°ã€boolï¼‰ã‚‚å¿…ãšå«ã‚ã‚‹</item>
                            <item>ç‰¹æ®Šå‹ï¼ˆé•·ã•ã€è§’åº¦ã€æ•°å€¤ã€æ–¹å‘ã€ç‚¹ã€å¹³é¢ã€å¤‰æ•°å˜ä½ã€è¦ç´ ã‚°ãƒ«ãƒ¼ãƒ—ã€æ³¨è¨˜ã‚¹ã‚¿ã‚¤ãƒ«ã€ææ–™ã€ã‚¹ã‚¤ãƒ¼ãƒ—æ–¹å‘ã€åšã¿ä»˜ã‘ã‚¿ã‚¤ãƒ—ã€ãƒ¢ãƒ¼ãƒ«ãƒ‰ä½ç½®ã€ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—ã€é€£çµè¨­å®šã€å½¢çŠ¶ã‚¿ã‚¤ãƒ—ã€å½¢çŠ¶ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€è¦ç´ ãªã©ï¼‰ã‚‚æ¼ã‚‰ã•ãšæŠ½å‡ºã™ã‚‹</item>
                            <item>å„å‹ã®descriptionã«ã¯ã€å½¢å¼ã®è©³ç´°ãƒ»åˆ¶ç´„ãƒ»ä¾‹ãªã©ã‚’å«ã‚ã‚‹</item>
                        </type_definitions>
                        <api_entries>
                            <item>ã€ŒAPIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è§£æã—ã€é–¢æ•°ãƒ»ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå®šç¾©ã‚’æŠ½å‡ºã™ã‚‹</item>
                            <kinds>
                                <function>entry_type = "function"</function>
                                <object_definition>entry_type = "object_definition"</object_definition>
                            </kinds>
                            <fields>
                                <item>name / description / category</item>
                                <item>params: name, position(0-based), type, description, is_required, default_value</item>
                                <item>properties: name, type, description</item>
                                <item>returns: type, description, is_arrayï¼ˆæˆ»ã‚Šå€¤ãŒç„¡ã„å ´åˆã¯ type ã‚’ "void" ã¨ã™ã‚‹ï¼‰</item>
                                <item>is_required ã¯ã€Œç©ºæ¬„ä¸å¯ã€ã€Œå¿…é ˆã€ã¨ã‚ã‚Œã° trueã€è¨˜è¼‰ãŒãªã‘ã‚Œã° false</item>
                                <item>implementation_status ã¯ã€Œæœªå®Ÿè£…ã€ã€Œä½¿ç”¨ã—ãªã„ã€ç­‰ã®å ´åˆ 'unimplemented'ã€ãã‚Œä»¥å¤–ã¯ 'implemented'</item>
                            </fields>
                        </api_entries>
                    </analysis_points>
                </guidelines>
                <format>{json_format}</format>
            </developer>
        </prompt>
        """

    @staticmethod
    def get_user_prompt() -> str:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—ã™ã‚‹"""
        return """
        ä»¥ä¸‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä¸Šè¨˜æ–¹é‡ã«å¾“ã£ã¦è§£æã—ã€å˜ä¸€ã®JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

        # é‡è¦: ãƒ‡ãƒ¼ã‚¿å‹ã®æŠ½å‡ºã«ã¤ã„ã¦
        - ã€Œå¼•æ•°ã®å‹ã¨æ›¸å¼ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰<strong>ã™ã¹ã¦ã®</strong>ãƒ‡ãƒ¼ã‚¿å‹ã‚’æ¼ã‚ŒãªãæŠ½å‡ºã—ã¦ãã ã•ã„
        - åŸºæœ¬ãƒ‡ãƒ¼ã‚¿å‹ï¼ˆæ–‡å­—åˆ—ã€æµ®å‹•å°æ•°ç‚¹ã€æ•´æ•°ã€boolï¼‰ã‚‚å«ã‚ã¦ãã ã•ã„
        - ç‰¹æ®Šãƒ‡ãƒ¼ã‚¿å‹ï¼ˆé•·ã•ã€è§’åº¦ã€æ•°å€¤ã€æ–¹å‘ã€ç‚¹ã€å¹³é¢ã€å¤‰æ•°å˜ä½ã€è¦ç´ ã‚°ãƒ«ãƒ¼ãƒ—ã€æ³¨è¨˜ã‚¹ã‚¿ã‚¤ãƒ«ã€ææ–™ã€ã‚¹ã‚¤ãƒ¼ãƒ—æ–¹å‘ã€åšã¿ä»˜ã‘ã‚¿ã‚¤ãƒ—ã€ãƒ¢ãƒ¼ãƒ«ãƒ‰ä½ç½®ã€ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—ã€é€£çµè¨­å®šã€å½¢çŠ¶ã‚¿ã‚¤ãƒ—ã€å½¢çŠ¶ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€è¦ç´ ãªã©ï¼‰ã‚‚å«ã‚ã¦ãã ã•ã„
        - å„ãƒ‡ãƒ¼ã‚¿å‹ã® description ã«ã¯è©³ç´°ãªä»•æ§˜ã€æ›¸å¼ã€å…·ä½“ä¾‹ã‚’å«ã‚ã¦ãã ã•ã„

        # è§£æå¯¾è±¡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
        ---
        {document}
        ---
        """

    @staticmethod
    def get_json_format() -> str:
        """JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹ã‚’å–å¾—ã™ã‚‹"""
        return """
        {
          "type_definitions": [
            {
              "name": "æ–‡å­—åˆ—",
              "description": "ä»»æ„ã®æ–‡å­—åˆ—ã€‚ä¾‹: "Sample""
            },
            {
              "name": "æµ®å‹•å°æ•°ç‚¹",
              "description": "æµ®å‹•å°æ•°ç‚¹æ•°ã€‚ä¾‹: 100.0"
            },
            {
              "name": "æ•´æ•°",
              "description": "æ•´æ•°å€¤ã€‚ä¾‹: 10"
            },
            {
              "name": "bool",
              "description": "çœŸå½å€¤ã€‚ä¾‹: true, false"
            },
            {
              "name": "é•·ã•",
              "description": "mmå˜ä½ã®æ•°å€¤ã€å¤‰æ•°è¦ç´ åã€å¼ã€‚ä¾‹: "100.0", "L1", "L1 / 2.0""
            },
            {
              "name": "è§’åº¦",
              "description": "åº¦(Â°)å˜ä½ã®æ•°å€¤ã€å¤‰æ•°è¦ç´ åã€å¼ã€‚ä¾‹: "30.0", "Angle1", "Angle1 * 0.2""
            },
            {
              "name": "ç‚¹",
              "description": "X,Y,Z(å¿…è¦ã«å¿œã˜ã¦W)ã®åº§æ¨™ã‚’ã‚³ãƒ³ãƒåŒºåˆ‡ã‚Šã§æŒ‡å®šã€‚ä¾‹: "100.0,50.0,0.0""
            },
            {
              "name": "å¹³é¢",
              "description": "æœ€åˆã®ã‚«ãƒ©ãƒ ã« "PL" ã‚’å«ã‚€å¹³é¢æŒ‡å®šã€‚ä¾‹: "PL,Z" ã¯ã‚°ãƒ­ãƒ¼ãƒãƒ«XYå¹³é¢"
            }
          ],
          "api_entries": [
            {
              "entry_type": "'function' ã¾ãŸã¯ 'object_definition'",
              "name": "åå‰",
              "description": "æ¦‚è¦èª¬æ˜",
              "category": "ã‚«ãƒ†ã‚´ãƒªå",
              "params": [
                {
                  "name": "ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å",
                  "position": "0-based ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹",
                  "type": "æ­£è¦åŒ–æ¸ˆã¿å‹å",
                  "description": "èª¬æ˜æ–‡",
                  "is_required": "true / false",
                  "default_value": "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¾ãŸã¯ null"
                }
              ],
              "properties": [
                {
                  "name": "ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£å",
                  "type": "æ­£è¦åŒ–æ¸ˆã¿å‹å",
                  "description": "èª¬æ˜æ–‡"
                }
              ],
              "returns": {
                "type": "æ­£è¦åŒ–æ¸ˆã¿å‹å (æˆ»ã‚Šå€¤ãªã—ã®å ´åˆã¯ "void")",
                "description": "èª¬æ˜æ–‡",
                "is_array": "true / false"
              },
              "notes": "è£œè¶³ (ã¾ãŸã¯ null)",
              "implementation_status": "'implemented' / 'unimplemented' / 'deprecated'"
            }
          ]
        }
        """

# ===== ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =====
class DataProcessor:
    """è§£æçµæœã‚’æ•´å½¢ã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹"""

    ARRAY_MARKERS = ("(é…åˆ—)", "é…åˆ—", "(array)", "[]")

    @staticmethod
    def normalize_type_name(type_name: str) -> str:
        """å‹åã‚’æ­£è¦åŒ–ã™ã‚‹"""
        if not isinstance(type_name, str):
            return type_name

        name = type_name.strip()
        if not name:
            return name

        is_array = DataProcessor._is_array_type(name)
        base_name = DataProcessor._strip_array_notation(name) if is_array else name

        mapping = {
            "string": "æ–‡å­—åˆ—",
            "str": "æ–‡å­—åˆ—",
            "text": "æ–‡å­—åˆ—",
            "float": "æµ®å‹•å°æ•°ç‚¹",
            "double": "æµ®å‹•å°æ•°ç‚¹",
            "number": "æµ®å‹•å°æ•°ç‚¹",
            "numeric": "æµ®å‹•å°æ•°ç‚¹",
            "decimal": "æµ®å‹•å°æ•°ç‚¹",
            "int": "æ•´æ•°",
            "integer": "æ•´æ•°",
            "long": "æ•´æ•°",
            "boolean": "bool",
            "bool": "bool",
            "length": "é•·ã•",
            "angle": "è§’åº¦",
            "direction": "æ–¹å‘",
            "direction2d": "æ–¹å‘(2D)",
            "plane": "å¹³é¢",
            "point": "ç‚¹",
            "point2d": "ç‚¹(2D)",
            "element": "è¦ç´ ",
            "elementid": "è¦ç´ ID",
            "elementgroup": "è¦ç´ ã‚°ãƒ«ãƒ¼ãƒ—",
            "material": "ææ–™",
            "style": "æ³¨è¨˜ã‚¹ã‚¿ã‚¤ãƒ«",
            "bstr": "BSTR",
            "é…åˆ—": "é…åˆ—",
            "void": "void",
        }

        key = DataProcessor._normalize_key(base_name)
        return mapping.get(key, base_name)

    @staticmethod
    def enrich_array_object_info(item: Dict[str, Any], type_value: str | None = None) -> None:
        """é…åˆ—æƒ…å ±ã‚’ä»˜åŠ ã™ã‚‹"""
        if type_value is None:
            type_value = item.get("type") or item.get("type_name")

        if not isinstance(type_value, str) or not type_value.strip():
            item["array_info"] = None
            return

        if DataProcessor._is_array_type(type_value):
            base = DataProcessor._strip_array_notation(type_value)
            item["array_info"] = {
                "is_array": True,
                "element_type": DataProcessor.normalize_type_name(base),
                "min_length": None,
                "max_length": None,
            }
        else:
            item["array_info"] = None

    @staticmethod
    def infer_is_required(param: Dict[str, Any]) -> None:
        """å¿…é ˆã‹ã©ã†ã‹ã‚’æ¨å®šã™ã‚‹"""
        constraints = param.get("constraints")
        if isinstance(constraints, list):
            constraints_text = " ".join(str(c) for c in constraints)
        elif isinstance(constraints, str):
            constraints_text = constraints
        else:
            constraints_text = ""

        description = param.get("description_raw") or param.get("description") or ""
        text = f"{constraints_text} {description}"

        required = ("ç©ºæ¬„ä¸å¯" in text) or ("å¿…é ˆ" in text)
        if ("ç©ºæ¬„å¯" in text) or ("ä»»æ„" in text):
            required = False

        existing = param.get("is_required")
        if existing is not None:
            required = required or DataProcessor._to_bool(existing)

        param["is_required"] = bool(required)

    @staticmethod
    def postprocess_parsed_result(parsed_result: Union[Dict, List]) -> Union[Dict, List]:
        """è§£æçµæœã®å¾Œå‡¦ç†ã‚’å®Ÿæ–½ã™ã‚‹"""
        if not isinstance(parsed_result, dict):
            return parsed_result

        type_definitions = parsed_result.get("type_definitions") or []
        parsed_result["type_definitions"] = type_definitions

        api_entries = parsed_result.get("api_entries") or []
        for entry in api_entries:
            params = entry.get("params") or []
            for index, param in enumerate(params):
                original_type = param.get("type")
                DataProcessor.enrich_array_object_info(param, original_type)
                if original_type is not None:
                    param["type"] = DataProcessor.normalize_type_name(original_type)
                DataProcessor.infer_is_required(param)
                param["is_required"] = DataProcessor._to_bool(param.get("is_required"))
                param["position"] = index
                param["default_value"] = DataProcessor._normalize_default_value(param.get("default_value"))
            entry["params"] = params

            properties = entry.get("properties") or []
            for prop in properties:
                original_type = prop.get("type")
                DataProcessor.enrich_array_object_info(prop, original_type)
                if original_type is not None:
                    prop["type"] = DataProcessor.normalize_type_name(original_type)
            entry["properties"] = properties

            returns = entry.get("returns")
            if isinstance(returns, dict):
                original_type = returns.get("type")
                is_array = False
                if original_type is None or original_type == "":
                    returns["type"] = "void"
                else:
                    is_array = DataProcessor._is_array_type(original_type)
                    base_type = DataProcessor._strip_array_notation(original_type) if is_array else original_type
                    returns["type"] = DataProcessor.normalize_type_name(base_type)
                provided_flag = DataProcessor._to_bool(returns.get("is_array"))
                returns["is_array"] = bool(provided_flag or is_array)
                returns["description"] = returns.get("description") or ""
            entry.setdefault("notes", None)
            entry.setdefault("implementation_status", "implemented")

        parsed_result["api_entries"] = api_entries

        return parsed_result

    @staticmethod
    def _normalize_key(value: str) -> str:
        """ãƒãƒƒãƒ”ãƒ³ã‚°ç”¨ã«ã‚­ãƒ¼ã‚’æ­£è¦åŒ–ã™ã‚‹"""
        return value.lower().replace(" ", "").replace("_", "").replace("-", "")

    @staticmethod
    def _is_array_type(type_name: str) -> bool:
        """å‹ãŒé…åˆ—ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹"""
        if not isinstance(type_name, str):
            return False
        normalized = type_name.strip().lower()
        return any(marker in normalized for marker in DataProcessor.ARRAY_MARKERS) or normalized.endswith("[]")

    @staticmethod
    def _strip_array_notation(type_name: str) -> str:
        """å‹åã‹ã‚‰é…åˆ—è¡¨ç¾ã‚’å–ã‚Šé™¤ã"""
        if not isinstance(type_name, str):
            return type_name
        stripped = type_name.replace("(é…åˆ—)", "").replace("(array)", "")
        stripped = stripped.strip()
        if stripped.endswith("[]"):
            stripped = stripped[:-2]
        if stripped.endswith("é…åˆ—"):
            stripped = stripped[:-len("é…åˆ—")]
        return stripped.strip()

    @staticmethod
    def _to_bool(value: Any) -> bool:
        """çœŸå½å€¤ã¨ã—ã¦è§£é‡ˆã™ã‚‹"""
        if isinstance(value, bool):
            return value
        if isinstance(value, str):
            normalized = value.strip().lower()
            if normalized in {"true", "1", "yes", "y"}:
                return True
            if normalized in {"false", "0", "no", "n"}:
                return False
        return bool(value)

    @staticmethod
    def _normalize_default_value(value: Any) -> Any:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’æ­£è¦åŒ–ã™ã‚‹"""
        if isinstance(value, str):
            lowered = value.strip().lower()
            if lowered in {"", "none", "null"}:
                return None
        return value

# ===== LLMãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =====
class LLMProcessor:
    """LLMã‚’åˆ©ç”¨ã—ãŸè§£æå‡¦ç†ã‚’ã¾ã¨ã‚ãŸãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹"""

    STRUCTURED_RESPONSE_FORMAT = {"type": "json_object"}

    @staticmethod
    def create_structured_llm() -> ChatOpenAI:
        """æ§‹é€ åŒ–å¿œç­”ã‚’å¼·åˆ¶ã™ã‚‹LLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç”Ÿæˆã™ã‚‹"""
        return ChatOpenAI(**Config.MODEL_CONFIG).bind(response_format=LLMProcessor.STRUCTURED_RESPONSE_FORMAT)

    @staticmethod
    def create_text_llm() -> ChatOpenAI:
        """è‡ªç”±å½¢å¼ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹LLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç”Ÿæˆã™ã‚‹"""
        return ChatOpenAI(**Config.MODEL_CONFIG)

    @staticmethod
    def parse_response(response: Any) -> Union[Dict, List]:
        """LLMã®å¿œç­”ã‚’ãƒ‘ãƒ¼ã‚¹ã™ã‚‹"""
        content = response.content
        print(f"Response type: {type(content)}")
        preview = str(content)
        print(f"Response content preview: {preview[:200]}...")

        try:
            if isinstance(content, str):
                parsed_result = json.loads(content)
            elif isinstance(content, (dict, list)):
                parsed_result = content
            else:
                parsed_result = json.loads(str(content))
            print("Parse succeeded.")
            return parsed_result
        except json.JSONDecodeError as exc:
            print(f"JSON parse error: {exc}")
            print("LLM output:", content)
            if isinstance(content, (dict, list)):
                return content
            raise
        except Exception as exc:
            print(f"Unexpected error while parsing LLM response: {exc}")
            print("LLM output:", content)
            raise

    @staticmethod
    def extract_from_responses_api(parsed_result: Union[Dict, List]) -> Union[Dict, List]:
        """Responses API v1å½¢å¼ã‹ã‚‰å®Ÿéš›ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æŠ½å‡ºã™ã‚‹"""
        if not isinstance(parsed_result, list) or len(parsed_result) == 0:
            return parsed_result

        print("Inspecting response for Responses API v1 envelope...")

        text_element = next((item for item in parsed_result if isinstance(item, dict) and item.get("type") == "text"), None)

        if text_element and "text" in text_element:
            try:
                actual_content = json.loads(text_element["text"])
                print("Extracted text element successfully.")
                return actual_content
            except json.JSONDecodeError as exc:
                print(f"JSON parse error inside text element: {exc}")
                print("Raw text element:", text_element["text"][:200])
                return parsed_result

        print("No text element found in response list.")
        return parsed_result

# ===== è‡ªå·±ä¿®æ­£æ©Ÿèƒ½ =====
class CodeQualityAnalyzer:

    """ã‚³ãƒ¼ãƒ‰å“è³ªåˆ†æã‚¯ãƒ©ã‚¹"""

    @staticmethod
    def analyze_code_quality(state: SelfCorrectionState, args: argparse.Namespace) -> SelfCorrectionState:
        """ã‚³ãƒ¼ãƒ‰ã®å“è³ªã‚’åˆ†æ"""
        print("ğŸ” ã‚³ãƒ¼ãƒ‰å“è³ªã®åˆ†æä¸­...")

        quality_issues = []

        # å“è³ªãƒã‚§ãƒƒã‚¯é …ç›®
        checks = [
            (
                "def " in state["current_code"] and "->" not in state["current_code"],
                "missing_type_hints",
                "medium",
                "é–¢æ•°ã«å‹ãƒ’ãƒ³ãƒˆãŒä¸è¶³ã—ã¦ã„ã¾ã™",
            ),
            (
                '"""' not in state["current_code"] and "'''" not in state["current_code"],
                "missing_docstrings",
                "low",
                "é–¢æ•°ã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ–‡å­—åˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™",
            ),
            (
                "try:" in state["current_code"] and "except" not in state["current_code"],
                "incomplete_error_handling",
                "high",
                "tryæ–‡ã«å¯¾å¿œã™ã‚‹exceptå¥ãŒä¸è¶³ã—ã¦ã„ã¾ã™",
            ),
            (
                "import " in state["current_code"] and "from typing import" not in state["current_code"],
                "missing_type_imports",
                "medium",
                "typingãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒä¸è¶³ã—ã¦ã„ã¾ã™",
            ),
        ]

        for condition, issue_type, severity, description in checks:
            if condition:
                quality_issues.append({"type": issue_type, "severity": severity, "description": description})

        state["errors"] = quality_issues
        state["quality_score"] = max(0, 100 - len(quality_issues) * Config.QUALITY_PENALTY_PER_ISSUE)

        print(f"å“è³ªã‚¹ã‚³ã‚¢: {state['quality_score']}/100")
        print(f"æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ: {len(quality_issues)}ä»¶")

        if args.verbose:
            for i, issue in enumerate(quality_issues, 1):
                print(f"  {i}. [{issue['severity'].upper()}] {issue['description']}")

        return state


class CodeCorrector:
    """ã‚³ãƒ¼ãƒ‰ä¿®æ­£ã‚¯ãƒ©ã‚¹"""

    @staticmethod
    def generate_corrections(state: SelfCorrectionState, args: argparse.Namespace) -> SelfCorrectionState:
        """æ¤œå‡ºã•ã‚ŒãŸå•é¡Œã«å¯¾ã™ã‚‹ä¿®æ­£ã‚’ç”Ÿæˆ"""
        if not state["errors"]:
            print("âœ… ä¿®æ­£ãŒå¿…è¦ãªå•é¡Œã¯ã‚ã‚Šã¾ã›ã‚“")
            return state

        if args.dry_run:
            print("ğŸ” ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¢ãƒ¼ãƒ‰: ä¿®æ­£ã¯ç”Ÿæˆã•ã‚Œã¾ã›ã‚“")
            return state

        print("ğŸ”§ ä¿®æ­£ã®ç”Ÿæˆä¸­...")

        # LLMã‚’ä½¿ç”¨ã—ã¦ä¿®æ­£ã‚’ç”Ÿæˆ
        llm = LLMProcessor.create_text_llm()
        correction_prompt = ChatPromptTemplate.from_messages(
            [
                ("system", "ã‚ãªãŸã¯å„ªç§€ãªPythoné–‹ç™ºè€…ã§ã™ã€‚ã‚³ãƒ¼ãƒ‰ã®å•é¡Œã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚"),
                (
                    "user",
                    f"""
                    ä»¥ä¸‹ã®Pythonã‚³ãƒ¼ãƒ‰ã®å•é¡Œã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ï¼š

                    å•é¡Œ:
                    {json.dumps(state["errors"], ensure_ascii=False, indent=2)}

                    ã‚³ãƒ¼ãƒ‰:
                    ```python
                    {state["current_code"]}
                    ```

                    ä¿®æ­£ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
                    """,
                ),
            ]
        )

        chain = correction_prompt | llm
        response = chain.invoke({})

        # ä¿®æ­£ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        corrected_code = response.content
        if isinstance(corrected_code, str):
            if "```python" in corrected_code:
                corrected_code = corrected_code.split("```python")[1].split("```")[0].strip()
            elif "```" in corrected_code:
                corrected_code = corrected_code.split("```")[1].split("```")[0].strip()

        state["correction_history"].append(
            {"iteration": state["corrections_made"] + 1, "errors": state["errors"], "corrected_code": corrected_code}
        )

        print(f"ä¿®æ­£ç‰ˆ {state['corrections_made'] + 1} ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
        return state

    @staticmethod
    def apply_corrections(state: SelfCorrectionState, args: argparse.Namespace) -> SelfCorrectionState:
        """ä¿®æ­£ã‚’é©ç”¨"""
        if not state["correction_history"]:
            return state

        if args.dry_run:
            print("ğŸ” ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¢ãƒ¼ãƒ‰: ä¿®æ­£ã¯é©ç”¨ã•ã‚Œã¾ã›ã‚“")
            return state

        print("ğŸ“ ä¿®æ­£ã‚’é©ç”¨ä¸­...")

        latest_correction = state["correction_history"][-1]
        state["current_code"] = latest_correction["corrected_code"]
        state["corrections_made"] += 1

        print(f"ä¿®æ­£ {state['corrections_made']} ã‚’é©ç”¨ã—ã¾ã—ãŸ")
        return state


class SelfCorrectionAgent:
    """è‡ªå·±ä¿®æ­£ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¯ãƒ©ã‚¹"""

    @staticmethod
    def should_continue_correcting(state: SelfCorrectionState, args: argparse.Namespace) -> str:
        """ä¿®æ­£ã‚’ç¶šè¡Œã™ã‚‹ã‹ã©ã†ã‹ã‚’åˆ¤æ–­"""
        if state["corrections_made"] >= state["max_corrections"]:
            print(f"âš ï¸ æœ€å¤§ä¿®æ­£å›æ•° {state['max_corrections']} ã«é”ã—ã¾ã—ãŸ")
            return "end"

        if state["quality_score"] >= args.quality_threshold:
            print(f"âœ… å“è³ªã‚¹ã‚³ã‚¢ãŒ{args.quality_threshold}ä»¥ä¸Šã«é”ã—ã¾ã—ãŸ")
            return "end"

        if not state["errors"]:
            print("âœ… ã‚¨ãƒ©ãƒ¼ãŒè§£æ±ºã•ã‚Œã¾ã—ãŸ")
            return "end"

        return "continue"

    @staticmethod
    def create_workflow(args: argparse.Namespace) -> StateGraph:
        """è‡ªå·±ä¿®æ­£ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ä½œæˆ"""
        workflow = StateGraph(SelfCorrectionState)

        # ãƒãƒ¼ãƒ‰ã®è¿½åŠ 
        workflow.add_node("analyze_quality", lambda state: CodeQualityAnalyzer.analyze_code_quality(state, args))
        workflow.add_node("generate_corrections", lambda state: CodeCorrector.generate_corrections(state, args))
        workflow.add_node("apply_corrections", lambda state: CodeCorrector.apply_corrections(state, args))

        # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã®è¨­å®šï¼ˆSTARTã‹ã‚‰æœ€åˆã®ãƒãƒ¼ãƒ‰ã¸ï¼‰
        workflow.set_entry_point("analyze_quality")

        # ã‚¨ãƒƒã‚¸ã®å®šç¾©
        workflow.add_edge("analyze_quality", "generate_corrections")
        workflow.add_edge("generate_corrections", "apply_corrections")

        # æ¡ä»¶åˆ†å²
        workflow.add_conditional_edges(
            "apply_corrections",
            lambda state: SelfCorrectionAgent.should_continue_correcting(state, args),
            {"continue": "analyze_quality", "end": END},
        )

        return workflow.compile()

    @staticmethod
    def execute(code: str, args: argparse.Namespace) -> Dict[str, Any]:
        """è‡ªå·±ä¿®æ­£ã‚’å®Ÿè¡Œ"""
        print("ğŸ¤– è‡ªå·±ä¿®æ­£ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’é–‹å§‹ã—ã¾ã™...")
        print(f"è¨­å®š: æœ€å¤§ä¿®æ­£å›æ•°={args.max_corrections}, å“è³ªé–¾å€¤={args.quality_threshold}")

        # åˆæœŸçŠ¶æ…‹ã®è¨­å®š
        initial_state = SelfCorrectionState(
            messages=[],
            current_code=code,
            errors=[],
            corrections_made=0,
            max_corrections=args.max_corrections,
            correction_history=[],
            quality_score=0.0,
        )

        # è‡ªå·±ä¿®æ­£ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿè¡Œ
        agent = SelfCorrectionAgent.create_workflow(args)
        final_state = agent.invoke(initial_state)

        print(f"ğŸ¯ è‡ªå·±ä¿®æ­£å®Œäº†ï¼æœ€çµ‚å“è³ªã‚¹ã‚³ã‚¢: {final_state['quality_score']}/100")
        print(f"ğŸ“Š å®Ÿè¡Œã•ã‚ŒãŸä¿®æ­£å›æ•°: {final_state['corrections_made']}")

        # ä¿®æ­£å±¥æ­´ã®ä¿å­˜
        if args.save_corrections and final_state["correction_history"]:
            correction_file = f"correction_history_{os.path.basename(__file__)}.json"
            with open(correction_file, "w", encoding="utf-8") as f:
                json.dump(final_state["correction_history"], f, ensure_ascii=False, indent=2)
            print(f"ä¿®æ­£å±¥æ­´ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {correction_file}")

        return {
            "corrected_code": final_state["current_code"],
            "final_quality_score": final_state["quality_score"],
            "corrections_made": final_state["corrections_made"],
            "correction_history": final_state["correction_history"],
        }


# ===== ãƒ¡ã‚¤ãƒ³å‡¦ç†é–¢æ•° =====
def analyze_api_document(args: argparse.Namespace) -> Dict[str, Any]:
    """APIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è§£æã‚’å®Ÿè¡Œ"""
    print("ğŸ¤– LLMã‚’ä½¿ã£ã¦APIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è§£æã—ã¦ã„ã¾ã™...")

    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®èª­ã¿è¾¼ã¿
    api_document_text = load_api_document(args.api_doc, args.api_arg)
    system_prompt_template = PromptManager.get_system_prompt()
    user_prompt_template = PromptManager.get_user_prompt()
    json_format_instructions = PromptManager.get_json_format()

    # LLMã®ä½œæˆã¨å®Ÿè¡Œ
    llm = LLMProcessor.create_structured_llm()
    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_prompt_template),
            ("user", user_prompt_template),
        ]
    )

    chain = prompt | llm
    response = chain.invoke(
        {
            "document": api_document_text,
            "json_format": json_format_instructions,
        }
    )

    # å¿œç­”ã®ãƒ‘ãƒ¼ã‚¹
    parsed_result = LLMProcessor.parse_response(response)

    # Responses API v1å½¢å¼ã®å‡¦ç†
    if isinstance(parsed_result, dict):
        print("âœ… å˜ä¸€ã®JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦æ­£ã—ããƒ‘ãƒ¼ã‚¹ã•ã‚Œã¾ã—ãŸ")
    else:
        parsed_result = LLMProcessor.extract_from_responses_api(parsed_result)

    # å¾Œå‡¦ç†ã®å®Ÿè¡Œ
    print("\nğŸ”„ è§£æçµæœã®å¾Œå‡¦ç†ã‚’å®Ÿè¡Œä¸­...")
    processed_result = DataProcessor.postprocess_parsed_result(parsed_result)

    return processed_result


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    try:
        # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®è§£æ
        args = parse_arguments()

        if args.verbose:
            print("ğŸ”§ è©³ç´°ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œä¸­...")
            print(f"APIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: {args.api_doc}")
            print(f"APIå¼•æ•°: {args.api_arg}")
            print(f"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {args.output}")
            print(f"è‡ªå·±ä¿®æ­£: {'æœ‰åŠ¹' if args.self_correct else 'ç„¡åŠ¹'}")
            if args.self_correct:
                print(f"æœ€å¤§ä¿®æ­£å›æ•°: {args.max_corrections}")
                print(f"å“è³ªé–¾å€¤: {args.quality_threshold}")

        # APIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è§£æ
        processed_result = analyze_api_document(args)

        # çµæœã®è¡¨ç¤ºã¨ä¿å­˜
        print("\nâœ… è§£æãŒå®Œäº†ã—ã€JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
        if args.verbose:
            print(json.dumps(processed_result, indent=2, ensure_ascii=False))
        save_parsed_result(processed_result, args.output)

        # è‡ªå·±ä¿®æ­£æ©Ÿèƒ½ã®å®Ÿè¡Œï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if args.self_correct:
            print("\nğŸ”§ è‡ªå·±ä¿®æ­£æ©Ÿèƒ½ã‚’å®Ÿè¡Œã—ã¾ã™...")

            # ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’èª­ã¿è¾¼ã¿
            current_file_path = __file__
            with open(current_file_path, "r", encoding="utf-8") as f:
                current_code = f.read()

            # è‡ªå·±ä¿®æ­£ã®å®Ÿè¡Œ
            corrected_result = SelfCorrectionAgent.execute(current_code, args)

            # ä¿®æ­£ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã®ä¿å­˜
            if corrected_result["corrections_made"] > 0:
                corrected_file_path = current_file_path + ".corrected"
                with open(corrected_file_path, "w", encoding="utf-8") as f:
                    f.write(corrected_result["corrected_code"])
                print(f"ä¿®æ­£ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {corrected_file_path}")

                if args.verbose:
                    print(f"æœ€çµ‚å“è³ªã‚¹ã‚³ã‚¢: {corrected_result['final_quality_score']}/100")
                    print(f"å®Ÿè¡Œã•ã‚ŒãŸä¿®æ­£å›æ•°: {corrected_result['corrections_made']}")
            else:
                print("âœ… ä¿®æ­£ã¯å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        print(f"ã‚¨ãƒ©ãƒ¼ã®ç¨®é¡: {type(e).__name__}")
        if "api_key" in str(e).lower():
            print("\nğŸ’¡ ãƒ’ãƒ³ãƒˆ: .envãƒ•ã‚¡ã‚¤ãƒ«ã«æ­£ã—ã„OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")


# ===== ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°å‡¦ç† =====
def parse_arguments():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’è§£æ"""
    parser = argparse.ArgumentParser(
        description="EVO.SHIP APIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè§£æãƒ„ãƒ¼ãƒ«",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=(
            "\nä½¿ç”¨ä¾‹:\n"
            "  # åŸºæœ¬çš„ãªAPIè§£æã®ã¿å®Ÿè¡Œ\n"
            "  python doc_paser.py\n\n"
            "  # è‡ªå·±ä¿®æ­£æ©Ÿèƒ½ã‚’æœ‰åŠ¹ã«ã—ã¦å®Ÿè¡Œ\n"
            "  python doc_paser.py --self-correct\n\n"
            "  # è‡ªå·±ä¿®æ­£ã®æœ€å¤§å›æ•°ã‚’æŒ‡å®š\n"
            "  python doc_parser.py --self-correct --max-corrections 5\n\n"
            "  # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æŒ‡å®š\n"
            "  python doc_paser.py --output output.json\n\n"
            "  # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æŒ‡å®š\n"
            "  python doc_paser.py --api-doc custom_api.txt --api-arg custom_arg.txt\n\n"
            "  # è©³ç´°ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ\n"
            "  python doc_paser.py --verbose\n"
        ),
    )

    # åŸºæœ¬ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument(
        "--api-doc",
        default=Config.DEFAULT_API_DOC_PATH,
        help=f"APIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {Config.DEFAULT_API_DOC_PATH})",
    )

    parser.add_argument(
        "--api-arg",
        default=Config.DEFAULT_API_ARG_PATH,
        help=f"APIå¼•æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {Config.DEFAULT_API_ARG_PATH})",
    )

    parser.add_argument(
        "--output",
        default=Config.DEFAULT_OUTPUT_PATH,
        help=f"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {Config.DEFAULT_OUTPUT_PATH})",
    )

    # è‡ªå·±ä¿®æ­£ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument("--self-correct", action="store_true", help="è‡ªå·±ä¿®æ­£æ©Ÿèƒ½ã‚’æœ‰åŠ¹ã«ã™ã‚‹")

    parser.add_argument(
        "--max-corrections",
        type=int,
        default=Config.DEFAULT_MAX_CORRECTIONS,
        help=f"è‡ªå·±ä¿®æ­£ã®æœ€å¤§å›æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {Config.DEFAULT_MAX_CORRECTIONS})",
    )

    parser.add_argument(
        "--quality-threshold",
        type=float,
        default=Config.DEFAULT_QUALITY_THRESHOLD,
        help=f"è‡ªå·±ä¿®æ­£ã‚’çµ‚äº†ã™ã‚‹å“è³ªã‚¹ã‚³ã‚¢ã®é–¾å€¤ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {Config.DEFAULT_QUALITY_THRESHOLD})",
    )

    # ãã®ä»–ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument("--verbose", action="store_true", help="è©³ç´°ãªãƒ­ã‚°ã‚’å‡ºåŠ›ã™ã‚‹")

    parser.add_argument("--dry-run", action="store_true", help="å®Ÿéš›ã®ä¿®æ­£ã¯è¡Œã‚ãšã€æ¤œå‡ºã•ã‚ŒãŸå•é¡Œã®ã¿ã‚’è¡¨ç¤ºã™ã‚‹")

    parser.add_argument("--save-corrections", action="store_true", help="ä¿®æ­£å±¥æ­´ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹")

    return parser.parse_args()


if __name__ == "__main__":
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã®è¨­å®š
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    if project_root not in sys.path:
        sys.path.insert(0, project_root)

    print(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹: {project_root}")
    print(f"Pythonãƒ‘ã‚¹ã«è¿½åŠ ã•ã‚Œã¾ã—ãŸ: {project_root in sys.path}")

    main()
